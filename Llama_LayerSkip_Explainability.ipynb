{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM/XB5lwttSCda7WIm20vBL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "809937db362e41f38a56964c20c42fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab28e6beb15143a49a2362fd5552634f",
              "IPY_MODEL_ef480cff5b5b423382d05294288fe88d",
              "IPY_MODEL_5c7537db9fb74f0da3eb58dc01771070"
            ],
            "layout": "IPY_MODEL_b9f68fef432d4181a310ef2aa42a09e3"
          }
        },
        "ab28e6beb15143a49a2362fd5552634f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3030cc3795f64854980fb3e4a61b5718",
            "placeholder": "​",
            "style": "IPY_MODEL_bf948144065e4696be5b1b79fd6a0d1e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ef480cff5b5b423382d05294288fe88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abe6300772d54bc5a264dbd3d2ec23a5",
            "max": 50495,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86eedb28f0b04ecdb15e0cd597248065",
            "value": 50495
          }
        },
        "5c7537db9fb74f0da3eb58dc01771070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98b0b16b03ba47ffa3a2eea7a4dc9b3e",
            "placeholder": "​",
            "style": "IPY_MODEL_0bc940f864904a6480ed03ddd62b37c6",
            "value": " 50.5k/50.5k [00:00&lt;00:00, 4.57MB/s]"
          }
        },
        "b9f68fef432d4181a310ef2aa42a09e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3030cc3795f64854980fb3e4a61b5718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf948144065e4696be5b1b79fd6a0d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abe6300772d54bc5a264dbd3d2ec23a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86eedb28f0b04ecdb15e0cd597248065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98b0b16b03ba47ffa3a2eea7a4dc9b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc940f864904a6480ed03ddd62b37c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "189a00f38e9a4ec3bf807cc5e5a28095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e40ef771d324afa8b5e1c8c3c893e3c",
              "IPY_MODEL_26571d1e41a54e9cbd6dbae33d59112d",
              "IPY_MODEL_8f40392046d04c7d8482f9fbf96152da"
            ],
            "layout": "IPY_MODEL_59575d76fb7a4090a67dca8bb37ddf73"
          }
        },
        "9e40ef771d324afa8b5e1c8c3c893e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d46e89a54349c096a613b76fa9572c",
            "placeholder": "​",
            "style": "IPY_MODEL_6780cb25f45040ff892aaa4f645d0893",
            "value": "tokenizer.json: 100%"
          }
        },
        "26571d1e41a54e9cbd6dbae33d59112d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_102013c852ef486ba6557d2eeba908c5",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_562000d5111c40f78cda7a827876f27f",
            "value": 17209920
          }
        },
        "8f40392046d04c7d8482f9fbf96152da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8899e4485c742e79ca65b6fd3f3512a",
            "placeholder": "​",
            "style": "IPY_MODEL_19635440391d48d582752ced4cc8cb5d",
            "value": " 17.2M/17.2M [00:00&lt;00:00, 32.5MB/s]"
          }
        },
        "59575d76fb7a4090a67dca8bb37ddf73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d46e89a54349c096a613b76fa9572c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6780cb25f45040ff892aaa4f645d0893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "102013c852ef486ba6557d2eeba908c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562000d5111c40f78cda7a827876f27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8899e4485c742e79ca65b6fd3f3512a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19635440391d48d582752ced4cc8cb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a57adaf99b3c42b0967d4a5b7eb88727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee0ca76dbad74000b1350c4f4013ca1e",
              "IPY_MODEL_170afc923653435eaa57bdb26a92aa09",
              "IPY_MODEL_e7a04477d1d74c49a0d7b8918f5d6825"
            ],
            "layout": "IPY_MODEL_969d15f8d6aa49839f8d6a7095edb50f"
          }
        },
        "ee0ca76dbad74000b1350c4f4013ca1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bb22e5b74e1438aa67cfcc9fccf2056",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff82f13a1eb4ec2a2e4b644a99039b0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "170afc923653435eaa57bdb26a92aa09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001f7820b1ec49dba4cf1f7ab41dc7a9",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a161e97b9fb4c4cac83b0985ef0bd6b",
            "value": 296
          }
        },
        "e7a04477d1d74c49a0d7b8918f5d6825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c4be9443e474c4c9c31c023999209bd",
            "placeholder": "​",
            "style": "IPY_MODEL_fb5780e4511548a996200e7c8b13a8d6",
            "value": " 296/296 [00:00&lt;00:00, 34.9kB/s]"
          }
        },
        "969d15f8d6aa49839f8d6a7095edb50f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb22e5b74e1438aa67cfcc9fccf2056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff82f13a1eb4ec2a2e4b644a99039b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "001f7820b1ec49dba4cf1f7ab41dc7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a161e97b9fb4c4cac83b0985ef0bd6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c4be9443e474c4c9c31c023999209bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5780e4511548a996200e7c8b13a8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b08abbcd969044c3bf5af71b7ecc3bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b39ff8f9075b4df79e5e85035ee8bf54",
              "IPY_MODEL_c6de1a999c1e4fdc95b62adc19a5e3e2",
              "IPY_MODEL_5aea5751e307435c80a74d4b0a189259"
            ],
            "layout": "IPY_MODEL_b5f49b8776fd4dc1a7dd0131cdfc4b04"
          }
        },
        "b39ff8f9075b4df79e5e85035ee8bf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41728056835d4df4acc1de6a7aebcbe9",
            "placeholder": "​",
            "style": "IPY_MODEL_b72d0ab49c504776aff50cc0885ebc95",
            "value": "config.json: 100%"
          }
        },
        "c6de1a999c1e4fdc95b62adc19a5e3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bb6cb46e77b4164ab8c5f8602484ca3",
            "max": 843,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7269e0d932a44e848087318ee7fe2437",
            "value": 843
          }
        },
        "5aea5751e307435c80a74d4b0a189259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec66d5cbd6224efa9a905bab3038d767",
            "placeholder": "​",
            "style": "IPY_MODEL_fbc97e318a8642b18c42bd36f63ea420",
            "value": " 843/843 [00:00&lt;00:00, 100kB/s]"
          }
        },
        "b5f49b8776fd4dc1a7dd0131cdfc4b04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41728056835d4df4acc1de6a7aebcbe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72d0ab49c504776aff50cc0885ebc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bb6cb46e77b4164ab8c5f8602484ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7269e0d932a44e848087318ee7fe2437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec66d5cbd6224efa9a905bab3038d767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbc97e318a8642b18c42bd36f63ea420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ebe1b1c09240b9af64a3a494fb6b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dad4af64f3e74d6ebecfa34c3c806172",
              "IPY_MODEL_5d4a71f8e4b14cf0a8363122a7f5e9e0",
              "IPY_MODEL_e5ced14f732146ccac0469503547c14f"
            ],
            "layout": "IPY_MODEL_7f18fd3ebdb2458abc71c211c54684de"
          }
        },
        "dad4af64f3e74d6ebecfa34c3c806172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ccb32fd508e45d2a66983d83d322065",
            "placeholder": "​",
            "style": "IPY_MODEL_fcf602d2152c43c9823733a295b47212",
            "value": "model.safetensors: 100%"
          }
        },
        "5d4a71f8e4b14cf0a8363122a7f5e9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362086409fea4ea19dec647b87a694d5",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a921995e33814aee904a3abb0aa1b0d3",
            "value": 2471645608
          }
        },
        "e5ced14f732146ccac0469503547c14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e47523db7b04c07931883907df22afb",
            "placeholder": "​",
            "style": "IPY_MODEL_ddd2038af69149f1b38b8d1a629f9d6f",
            "value": " 2.47G/2.47G [00:17&lt;00:00, 125MB/s]"
          }
        },
        "7f18fd3ebdb2458abc71c211c54684de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ccb32fd508e45d2a66983d83d322065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf602d2152c43c9823733a295b47212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "362086409fea4ea19dec647b87a694d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a921995e33814aee904a3abb0aa1b0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e47523db7b04c07931883907df22afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd2038af69149f1b38b8d1a629f9d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b619b46671c0485a9ecff55d018e8fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b0b97764a954d58a7f8cc480b083ca5",
              "IPY_MODEL_6327b0adaadb45a097add72c93660a34",
              "IPY_MODEL_0ac041eb1f0c4a3cb8a36a93a5b13d98"
            ],
            "layout": "IPY_MODEL_be4083b26acc4ef8a7b1b9b595bac4b0"
          }
        },
        "9b0b97764a954d58a7f8cc480b083ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c0dc3186124110b66de51f3639c5a8",
            "placeholder": "​",
            "style": "IPY_MODEL_dfb7e36f5b54433b83ac257d8d459492",
            "value": "generation_config.json: 100%"
          }
        },
        "6327b0adaadb45a097add72c93660a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e72427cbc04724ba02fd1f3cf4cfd9",
            "max": 126,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a8830d0c5b046bca8c0230958212e56",
            "value": 126
          }
        },
        "0ac041eb1f0c4a3cb8a36a93a5b13d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fb80cdfe72b435a9963fad026a60647",
            "placeholder": "​",
            "style": "IPY_MODEL_1f363c3f66a54764817a94efb409735d",
            "value": " 126/126 [00:00&lt;00:00, 16.7kB/s]"
          }
        },
        "be4083b26acc4ef8a7b1b9b595bac4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c0dc3186124110b66de51f3639c5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb7e36f5b54433b83ac257d8d459492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3e72427cbc04724ba02fd1f3cf4cfd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a8830d0c5b046bca8c0230958212e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fb80cdfe72b435a9963fad026a60647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f363c3f66a54764817a94efb409735d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9bb7a05184147939f156abd55718b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cc41754db444938a07847585637fa21",
              "IPY_MODEL_e60eae335a11426da67d59fb2d7ca9d4",
              "IPY_MODEL_beda5ece15794e82897856c9b944211f"
            ],
            "layout": "IPY_MODEL_e7dd73ea3daf41d799eb2d8553643c7d"
          }
        },
        "3cc41754db444938a07847585637fa21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f7eb0b4c9541f7b2a6817435b403ff",
            "placeholder": "​",
            "style": "IPY_MODEL_af5e365bd15f4df6bdca43782361640a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e60eae335a11426da67d59fb2d7ca9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5290e416450041dca931ecb4486f3e60",
            "max": 50500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc1f364a3b2446f38b62efcbf8b956f3",
            "value": 50500
          }
        },
        "beda5ece15794e82897856c9b944211f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ec10849e375436fad5070a0309a3eab",
            "placeholder": "​",
            "style": "IPY_MODEL_064d683432e148b1a943300940c6c971",
            "value": " 50.5k/50.5k [00:00&lt;00:00, 5.80MB/s]"
          }
        },
        "e7dd73ea3daf41d799eb2d8553643c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f7eb0b4c9541f7b2a6817435b403ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af5e365bd15f4df6bdca43782361640a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5290e416450041dca931ecb4486f3e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc1f364a3b2446f38b62efcbf8b956f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ec10849e375436fad5070a0309a3eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064d683432e148b1a943300940c6c971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a607ea3a66994eaf9adcd77f0e89a9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2fe60b55efd4408b6ef3f1d426e3742",
              "IPY_MODEL_32c9f3345ea942ce987a2812197fbfa8",
              "IPY_MODEL_9252d5dbb79b4f9fb3a8706b7306c988"
            ],
            "layout": "IPY_MODEL_df0ab7d610fa42498773d5f65ac7f599"
          }
        },
        "b2fe60b55efd4408b6ef3f1d426e3742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_767b53ba64f34fc39e4815480c3eba11",
            "placeholder": "​",
            "style": "IPY_MODEL_160ed651b6d8425397932fd9a53fd91b",
            "value": "tokenizer.json: 100%"
          }
        },
        "32c9f3345ea942ce987a2812197fbfa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a02f1dfe4d45be9febf6634ed50185",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e46a1ae6b5a5424780e84376e4176546",
            "value": 9085657
          }
        },
        "9252d5dbb79b4f9fb3a8706b7306c988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae3f57f2cb94d54a5f922fb1a628f51",
            "placeholder": "​",
            "style": "IPY_MODEL_a73acd6cb9164250a9ebb61f7c7518f2",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 18.9MB/s]"
          }
        },
        "df0ab7d610fa42498773d5f65ac7f599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "767b53ba64f34fc39e4815480c3eba11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160ed651b6d8425397932fd9a53fd91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62a02f1dfe4d45be9febf6634ed50185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46a1ae6b5a5424780e84376e4176546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ae3f57f2cb94d54a5f922fb1a628f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73acd6cb9164250a9ebb61f7c7518f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "582b84838ce04858aa4ba8cac204097c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d021801d16d49aba78a36af8d9501e8",
              "IPY_MODEL_a0ba239b8a1e46bdb9afcd7a746035df",
              "IPY_MODEL_d042a7cf63c44e8e852629fa66d7ea7e"
            ],
            "layout": "IPY_MODEL_065d0ec3db044e96ad32d6637b4ccffe"
          }
        },
        "6d021801d16d49aba78a36af8d9501e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_615975f3f77a40c18587d6dad5951354",
            "placeholder": "​",
            "style": "IPY_MODEL_b50701da72b54696bfb212a3ec9476e8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a0ba239b8a1e46bdb9afcd7a746035df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856e9581a2e548b3a5e2c5504020a27f",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4a4c08ec94d42f4bdde5a554efd02ed",
            "value": 301
          }
        },
        "d042a7cf63c44e8e852629fa66d7ea7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_434f8dfae716433193f1b5585faedb46",
            "placeholder": "​",
            "style": "IPY_MODEL_11edb704b71d4b37a357e3e0f902d04b",
            "value": " 301/301 [00:00&lt;00:00, 38.2kB/s]"
          }
        },
        "065d0ec3db044e96ad32d6637b4ccffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615975f3f77a40c18587d6dad5951354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b50701da72b54696bfb212a3ec9476e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "856e9581a2e548b3a5e2c5504020a27f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a4c08ec94d42f4bdde5a554efd02ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "434f8dfae716433193f1b5585faedb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11edb704b71d4b37a357e3e0f902d04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "945325b3e88442fc963388e242bdc87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eccf66d6e64426ca7ee1ad85b1725c9",
              "IPY_MODEL_e4297bd2ad734d25a09e93f7a398807b",
              "IPY_MODEL_2eb41da80d374d63a62a1adbf46d7715"
            ],
            "layout": "IPY_MODEL_899279136fd141259b57492aca2b12c5"
          }
        },
        "8eccf66d6e64426ca7ee1ad85b1725c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3790311426ad492fb31f111be4a0cde6",
            "placeholder": "​",
            "style": "IPY_MODEL_8f34749fbf844cd59cfab3135f15a4ab",
            "value": "100%"
          }
        },
        "e4297bd2ad734d25a09e93f7a398807b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a97a206328b4310823a7c25ab49ffb5",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8be7fbe2929e4ea6bc979038c4fa8407",
            "value": 10
          }
        },
        "2eb41da80d374d63a62a1adbf46d7715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23fa9088f17046c4a185f8e05ae97d9a",
            "placeholder": "​",
            "style": "IPY_MODEL_5043b973ed0e4aaab12aff664c4f78f1",
            "value": " 10/10 [00:00&lt;00:00, 18.84it/s]"
          }
        },
        "899279136fd141259b57492aca2b12c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3790311426ad492fb31f111be4a0cde6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f34749fbf844cd59cfab3135f15a4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a97a206328b4310823a7c25ab49ffb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be7fbe2929e4ea6bc979038c4fa8407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23fa9088f17046c4a185f8e05ae97d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5043b973ed0e4aaab12aff664c4f78f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "871450e3c2f24bc5a3d781e51d247e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90128cbe40f242b88547f7466c13f22d",
              "IPY_MODEL_f09cb21e8f2b49008efbde163707470d",
              "IPY_MODEL_f15ef474efdd4dc1baa8b1ebea535f9e"
            ],
            "layout": "IPY_MODEL_eaa7db903ef04e1ba081d3d189a87026"
          }
        },
        "90128cbe40f242b88547f7466c13f22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0316f828ee654458937e7b1fcdaffed0",
            "placeholder": "​",
            "style": "IPY_MODEL_18dc2e55586845068137c92f8355ee4f",
            "value": "100%"
          }
        },
        "f09cb21e8f2b49008efbde163707470d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1769d73328fb4971b0a72c7f20c996f1",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85910e0dfc4d405889f1233a447483db",
            "value": 10
          }
        },
        "f15ef474efdd4dc1baa8b1ebea535f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb49b009f5c643c5afaf1b6c34060438",
            "placeholder": "​",
            "style": "IPY_MODEL_c33140f6f1d444799c65c16d74ce37a0",
            "value": " 10/10 [00:00&lt;00:00, 29.97it/s]"
          }
        },
        "eaa7db903ef04e1ba081d3d189a87026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0316f828ee654458937e7b1fcdaffed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18dc2e55586845068137c92f8355ee4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1769d73328fb4971b0a72c7f20c996f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85910e0dfc4d405889f1233a447483db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb49b009f5c643c5afaf1b6c34060438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33140f6f1d444799c65c16d74ce37a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "102a95b75adf4274a9c003fe96f59fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84262af0802f4cdaabb5aeaa1174d408",
              "IPY_MODEL_ef71ae9569424b368d54fccacd52ae91",
              "IPY_MODEL_ee6c3f2362b44c1db8f2c32a8e5db80e"
            ],
            "layout": "IPY_MODEL_851c2b8b8315414aa1f014ee40cfbd56"
          }
        },
        "84262af0802f4cdaabb5aeaa1174d408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7108cbf1be74fb4a42106752250a2c5",
            "placeholder": "​",
            "style": "IPY_MODEL_5d9c094532bd425ab57f21f5c9459bae",
            "value": "100%"
          }
        },
        "ef71ae9569424b368d54fccacd52ae91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f2ebab7155144ab962975165c09de29",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2c3195f39e14cf59f50ea7a82356d81",
            "value": 10
          }
        },
        "ee6c3f2362b44c1db8f2c32a8e5db80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b5d58af7bcb486491cd053eed5af15f",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec198e809514e24a07427a6b619c8db",
            "value": " 10/10 [00:00&lt;00:00, 30.38it/s]"
          }
        },
        "851c2b8b8315414aa1f014ee40cfbd56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7108cbf1be74fb4a42106752250a2c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d9c094532bd425ab57f21f5c9459bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f2ebab7155144ab962975165c09de29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c3195f39e14cf59f50ea7a82356d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b5d58af7bcb486491cd053eed5af15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec198e809514e24a07427a6b619c8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwizgird/DATAENLIGHT_AI_NLP/blob/main/Llama_LayerSkip_Explainability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3_cZy4MpwZO",
        "outputId": "d2a28ffe-a7eb-46d4-95a4-e02b8268957f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformer_lens\n",
        "%pip install circuitsvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnwIdUYmVqVN",
        "outputId": "ca9a73b5-fd72-4971-ed6a-ff388be32c62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.15.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.5.2)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.8.1)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.43 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.51.3)\n",
            "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer_lens)\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.13.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.19.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.7.1->transformer_lens)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.11.15)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading wadler_lindig-0.1.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.2->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43->transformer_lens) (0.21.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.11.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.19.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
            "Downloading transformer_lens-2.15.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.5-py3-none-any.whl (20 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers-stream-generator\n",
            "  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12426 sha256=a7d14449a467f32e73f0a10a718be84f8d1d71a0fd43a05baf63f69eb283c4a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/e8/f0/b3c58c12d1ffe60bcc8c7d121115f26b2c1878653edfca48db\n",
            "Successfully built transformers-stream-generator\n",
            "Installing collected packages: better-abc, xxhash, wadler-lindig, fsspec, fancy-einsum, dill, beartype, multiprocess, jaxtyping, datasets, transformers-stream-generator, transformer_lens\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 datasets-3.5.0 dill-0.3.8 fancy-einsum-0.0.3 fsspec-2024.12.0 jaxtyping-0.3.2 multiprocess-0.70.16 transformer_lens-2.15.0 transformers-stream-generator-0.0.5 wadler-lindig-0.1.5 xxhash-3.5.0\n",
            "Collecting circuitsvis\n",
            "  Downloading circuitsvis-1.43.3-py3-none-any.whl.metadata (983 bytes)\n",
            "Requirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from circuitsvis) (8.6.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from circuitsvis) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from circuitsvis) (2.6.0+cu124)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->circuitsvis) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.1->circuitsvis) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.1->circuitsvis) (3.0.2)\n",
            "Downloading circuitsvis-1.43.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: circuitsvis\n",
            "Successfully installed circuitsvis-1.43.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JSbSO3Bqvlse"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Deep Learning Librariers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from copy import deepcopy\n",
        "\n",
        "#Importing ML and Visualization libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "vpq2ox7iO8_S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import transformer_lens librariers\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, FactoredMatrix\n",
        "\n",
        "import circuitsvis as cv\n",
        "# Testing that the library works\n",
        "cv.examples.hello(\"Neel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "bGoTR8edVqfh",
        "outputId": "bf5c794d-70dd-4847-a59a-ff29f43c5e50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7db8b2e5d510>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-d4d62f69-8e90\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-d4d62f69-8e90\",\n",
              "      Hello,\n",
              "      {\"name\": \"Neel\"}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating the differences between Llama 2 Base and Llama LayerSkip architecture"
      ],
      "metadata": {
        "id": "b-OauHM4Oo6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install transformers torch accelerate sentencepiece"
      ],
      "metadata": {
        "id": "CAoRHn4qPxRu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uploading llama-2-7B\n",
        "#model_id = \"facebook/layerskip-llama2-7B\"\n",
        "model_id = \"facebook/layerskip-llama3.2-1B\""
      ],
      "metadata": {
        "id": "rGrAcfJWPAsZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN_DATAENLIGHT')"
      ],
      "metadata": {
        "id": "NNzeQv7vQ4cC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example: Get token from environment variable\n",
        "# hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "# Example: Directly paste token (use with caution)\n",
        "# hf_token = \"hf_YOUR_ACCESS_TOKEN_HERE\" # Replace with your actual token\n",
        "\n",
        "# Check if a token is provided (useful if not using CLI login consistently)\n",
        "if hf_token is None and 'HUGGINGFACE_TOKEN' in os.environ:\n",
        "    hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "    print(\"Using Hugging Face token from environment variable.\")\n",
        "elif hf_token:\n",
        "     print(\"Using Hugging Face token provided directly in the script.\")\n",
        "else:\n",
        "    print(\"Attempting to load model without explicit token (relies on CLI login or cached credentials).\")\n",
        "    # Set token to True to explicitly use cached token if available after CLI login\n",
        "    # hf_token = True # Or None if you want to rely purely on implicit discovery\n",
        "\n",
        "# --- Loading Tokenizer ---\n",
        "print(f\"Loading tokenizer for model: {model_id}\")\n",
        "try:\n",
        "    # Load the tokenizer associated with the Llama-2-7b model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_id,\n",
        "        token=hf_token # Pass token if using Method 2 or explicitly using cached token\n",
        "    )\n",
        "    print(\"Tokenizer loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")\n",
        "    print(\"Please ensure you have requested and been granted access to the model on Hugging Face:\")\n",
        "    print(f\"https://huggingface.co/{model_id}\")\n",
        "    print(\"And that you are properly authenticated (e.g., via `huggingface-cli login`).\")\n",
        "    exit() # Exit if tokenizer fails, as model loading will also fail\n",
        "\n",
        "# --- Loading Model ---\n",
        "print(f\"Loading model: {model_id}\")\n",
        "print(\"This may take a while and require significant RAM/VRAM...\")\n",
        "\n",
        "try:\n",
        "    # Load the model\n",
        "    # device_map='auto' uses Accelerate to automatically distribute layers across GPU(s) and CPU RAM\n",
        "    # torch_dtype=torch.float16 uses half-precision for less memory usage (requires compatible GPU)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        token=hf_token,               # Pass token if needed\n",
        "        torch_dtype=torch.float16,    # Use float16 to save memory (requires GPU)\n",
        "                                      # Use torch.bfloat16 for Ampere+ GPUs for better balance\n",
        "                                      # Omit or use torch.float32 for CPU or if float16 causes issues\n",
        "        device_map=\"auto\",            # Automatically map layers to available devices (GPU/CPU)\n",
        "                                      # Requires 'accelerate' library\n",
        "                                      # Use device_map='cuda:0' to force to a specific GPU\n",
        "                                      # Omit device_map to load entirely on CPU (requires LOTS of RAM)\n",
        "        # trust_remote_code=True      # Sometimes needed for specific model implementations,\n",
        "                                      # but generally try without it first for official models like Llama.\n",
        "                                      # Only set to True if you trust the source code.\n",
        "    )\n",
        "    print(\"Model loaded successfully.\")\n",
        "    print(f\"Model device map: {model.hf_device_map}\") # Show how the model is distributed\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Potential reasons:\")\n",
        "    print(\"- Ensure you have enough RAM (CPU loading) or VRAM (GPU loading). Llama-7B needs ~14GB for float16.\")\n",
        "    print(\"- Double-check authentication and model access permissions.\")\n",
        "    print(\"- Ensure 'accelerate' is installed if using device_map='auto'.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "809937db362e41f38a56964c20c42fb1",
            "ab28e6beb15143a49a2362fd5552634f",
            "ef480cff5b5b423382d05294288fe88d",
            "5c7537db9fb74f0da3eb58dc01771070",
            "b9f68fef432d4181a310ef2aa42a09e3",
            "3030cc3795f64854980fb3e4a61b5718",
            "bf948144065e4696be5b1b79fd6a0d1e",
            "abe6300772d54bc5a264dbd3d2ec23a5",
            "86eedb28f0b04ecdb15e0cd597248065",
            "98b0b16b03ba47ffa3a2eea7a4dc9b3e",
            "0bc940f864904a6480ed03ddd62b37c6",
            "189a00f38e9a4ec3bf807cc5e5a28095",
            "9e40ef771d324afa8b5e1c8c3c893e3c",
            "26571d1e41a54e9cbd6dbae33d59112d",
            "8f40392046d04c7d8482f9fbf96152da",
            "59575d76fb7a4090a67dca8bb37ddf73",
            "20d46e89a54349c096a613b76fa9572c",
            "6780cb25f45040ff892aaa4f645d0893",
            "102013c852ef486ba6557d2eeba908c5",
            "562000d5111c40f78cda7a827876f27f",
            "a8899e4485c742e79ca65b6fd3f3512a",
            "19635440391d48d582752ced4cc8cb5d",
            "a57adaf99b3c42b0967d4a5b7eb88727",
            "ee0ca76dbad74000b1350c4f4013ca1e",
            "170afc923653435eaa57bdb26a92aa09",
            "e7a04477d1d74c49a0d7b8918f5d6825",
            "969d15f8d6aa49839f8d6a7095edb50f",
            "6bb22e5b74e1438aa67cfcc9fccf2056",
            "6ff82f13a1eb4ec2a2e4b644a99039b0",
            "001f7820b1ec49dba4cf1f7ab41dc7a9",
            "1a161e97b9fb4c4cac83b0985ef0bd6b",
            "8c4be9443e474c4c9c31c023999209bd",
            "fb5780e4511548a996200e7c8b13a8d6",
            "b08abbcd969044c3bf5af71b7ecc3bce",
            "b39ff8f9075b4df79e5e85035ee8bf54",
            "c6de1a999c1e4fdc95b62adc19a5e3e2",
            "5aea5751e307435c80a74d4b0a189259",
            "b5f49b8776fd4dc1a7dd0131cdfc4b04",
            "41728056835d4df4acc1de6a7aebcbe9",
            "b72d0ab49c504776aff50cc0885ebc95",
            "9bb6cb46e77b4164ab8c5f8602484ca3",
            "7269e0d932a44e848087318ee7fe2437",
            "ec66d5cbd6224efa9a905bab3038d767",
            "fbc97e318a8642b18c42bd36f63ea420",
            "67ebe1b1c09240b9af64a3a494fb6b19",
            "dad4af64f3e74d6ebecfa34c3c806172",
            "5d4a71f8e4b14cf0a8363122a7f5e9e0",
            "e5ced14f732146ccac0469503547c14f",
            "7f18fd3ebdb2458abc71c211c54684de",
            "7ccb32fd508e45d2a66983d83d322065",
            "fcf602d2152c43c9823733a295b47212",
            "362086409fea4ea19dec647b87a694d5",
            "a921995e33814aee904a3abb0aa1b0d3",
            "6e47523db7b04c07931883907df22afb",
            "ddd2038af69149f1b38b8d1a629f9d6f",
            "b619b46671c0485a9ecff55d018e8fa1",
            "9b0b97764a954d58a7f8cc480b083ca5",
            "6327b0adaadb45a097add72c93660a34",
            "0ac041eb1f0c4a3cb8a36a93a5b13d98",
            "be4083b26acc4ef8a7b1b9b595bac4b0",
            "c4c0dc3186124110b66de51f3639c5a8",
            "dfb7e36f5b54433b83ac257d8d459492",
            "f3e72427cbc04724ba02fd1f3cf4cfd9",
            "8a8830d0c5b046bca8c0230958212e56",
            "5fb80cdfe72b435a9963fad026a60647",
            "1f363c3f66a54764817a94efb409735d"
          ]
        },
        "id": "_naQXwi-QRK-",
        "outputId": "7a8c80f3-a34b-4a16-ec48-b4bf3ef29348"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Hugging Face token provided directly in the script.\n",
            "Loading tokenizer for model: facebook/layerskip-llama3.2-1B\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "809937db362e41f38a56964c20c42fb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "189a00f38e9a4ec3bf807cc5e5a28095"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a57adaf99b3c42b0967d4a5b7eb88727"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded successfully.\n",
            "Loading model: facebook/layerskip-llama3.2-1B\n",
            "This may take a while and require significant RAM/VRAM...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b08abbcd969044c3bf5af71b7ecc3bce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67ebe1b1c09240b9af64a3a494fb6b19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/126 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b619b46671c0485a9ecff55d018e8fa1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "Model device map: {'': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skipLayerModel = model\n",
        "print(skipLayerModel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtjA_LFhVqRP",
        "outputId": "d11c3a89-b75c-4f52-e7f2-67a523e45cdf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-15): 16 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
            "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining Assistant model for Drafting Phase of Speculative Decoding\n",
        "(Method 1 - Direct Engineering)"
      ],
      "metadata": {
        "id": "PJ2tflE5hiNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deriveAssistantModel(model : torch.nn.Module, earlyExitLayer : int):\n",
        "    generationConfig = model.generation_config\n",
        "    weightsMemory = {id(w): w for w in model.parameters()}\n",
        "    #clone main model with shared weights\n",
        "    assistantModel = deepcopy(model, memo = weightsMemory)\n",
        "    # Apply early exit determined by hyperparameter\n",
        "    assistantModel.model.layers = assistantModel.model.layers[:earlyExitLayer]\n",
        "    del assistantModel.model.layers[earlyExitLayer:]\n",
        "    assistantModel.generation_config = generationConfig\n",
        "    return assistantModel\n"
      ],
      "metadata": {
        "id": "DwrnCbCihdTb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlyExitLayer = 16\n",
        "device = utils.get_device()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvhEIAjAkDRZ",
        "outputId": "69664801-5bf2-4adb-a742-4f2fd34bf9c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXFpEEKgwaIE",
        "outputId": "2deb0ed0-916f-4322-c9b7-fd2b8835655a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skipLayerModel.to(device)\n",
        "derivedAssistantModel = deriveAssistantModel(skipLayerModel, earlyExitLayer)\n",
        "derivedAssistantModel.to(device)\n",
        "del skipLayerModel"
      ],
      "metadata": {
        "id": "WoMNZJhvj2z6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(derivedAssistantModel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7iZuf7oj2-d",
        "outputId": "7ef30bc6-5c15-4fb3-ea0b-a3ce1730bc8b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-15): 16 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
            "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "derivedAssistantModel.generation_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJvF-Z28mi4b",
        "outputId": "e0d4e1b5-4d6f-45c8-94c2-0a4fdec6fe10"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerationConfig {\n",
              "  \"bos_token_id\": 128000,\n",
              "  \"eos_token_id\": 128001\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "derivedAssistantModel.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSieD83jmi-x",
        "outputId": "9266d125-7a94-409f-bd80-2ceb18acaf55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 128000,\n",
              "  \"eos_token_id\": 128001,\n",
              "  \"head_dim\": 64,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 2048,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 8192,\n",
              "  \"max_position_embeddings\": 131072,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 16,\n",
              "  \"num_key_value_heads\": 8,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"rms_norm_eps\": 1e-05,\n",
              "  \"rope_scaling\": {\n",
              "    \"factor\": 32.0,\n",
              "    \"high_freq_factor\": 4.0,\n",
              "    \"low_freq_factor\": 1.0,\n",
              "    \"original_max_position_embeddings\": 8192,\n",
              "    \"rope_type\": \"llama3\"\n",
              "  },\n",
              "  \"rope_theta\": 500000.0,\n",
              "  \"tie_word_embeddings\": true,\n",
              "  \"torch_dtype\": \"float16\",\n",
              "  \"transformers_version\": \"4.51.3\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 128256\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del derivedAssistantModel"
      ],
      "metadata": {
        "id": "JZylurkux-bO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoModelForCausalLM\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_id, token=hf_token)\n",
        "original_num_layers = config.num_hidden_layers\n",
        "new_num_layers = earlyExitLayer\n",
        "config.num_hidden_layers = new_num_layers\n",
        "print(f\"Modified config to have {new_num_layers} layers.\")\n",
        "\n",
        "# Attempt to load model with modified config and PRE-TRAINED weights\n",
        "try:\n",
        "    print(\"Attempting to load pre-trained weights with modified config...\")\n",
        "    # This will likely FAIL or WARN loudly about mismatched weights!\n",
        "    model_modified = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        config=config, # Pass the modified config\n",
        "        token=hf_token,\n",
        "        # Add quantization, device_map etc. as needed\n",
        "        device_map=\"auto\",\n",
        "        # You might need ignore_mismatched_sizes=True for it to even load *something*\n",
        "        # ignore_mismatched_sizes=True\n",
        "    )\n",
        "    print(\"Model loaded with modified config (check warnings!).\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR loading model with modified config: {e}\")\n",
        "    print(\"This usually happens because the pre-trained checkpoint weights\")\n",
        "    print(f\"are for {original_num_layers} layers, not {new_num_layers}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZoe3mRBwC0c",
        "outputId": "87e373b3-ec43-4319-813b-bea520c2cf93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified config to have 16 layers.\n",
            "Attempting to load pre-trained weights with modified config...\n",
            "Model loaded with modified config (check warnings!).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_modified.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrCxG93xykn2",
        "outputId": "5d091ec7-5e5e-4340-eee5-2c89f9e2caa5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 128000,\n",
              "  \"eos_token_id\": 128001,\n",
              "  \"head_dim\": 64,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 2048,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 8192,\n",
              "  \"max_position_embeddings\": 131072,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 16,\n",
              "  \"num_key_value_heads\": 8,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"rms_norm_eps\": 1e-05,\n",
              "  \"rope_scaling\": {\n",
              "    \"factor\": 32.0,\n",
              "    \"high_freq_factor\": 4.0,\n",
              "    \"low_freq_factor\": 1.0,\n",
              "    \"original_max_position_embeddings\": 8192,\n",
              "    \"rope_type\": \"llama3\"\n",
              "  },\n",
              "  \"rope_theta\": 500000.0,\n",
              "  \"tie_word_embeddings\": true,\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.51.3\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 128256\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assitantModel = model_modified"
      ],
      "metadata": {
        "id": "yU0HYr_0ytWh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assitantModel.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZwAbjSizRjG",
        "outputId": "43deb0a7-5ec1-4c53-b8e7-c21a099e97ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 128000,\n",
              "  \"eos_token_id\": 128001,\n",
              "  \"head_dim\": 64,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 2048,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 8192,\n",
              "  \"max_position_embeddings\": 131072,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 16,\n",
              "  \"num_key_value_heads\": 8,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"rms_norm_eps\": 1e-05,\n",
              "  \"rope_scaling\": {\n",
              "    \"factor\": 32.0,\n",
              "    \"high_freq_factor\": 4.0,\n",
              "    \"low_freq_factor\": 1.0,\n",
              "    \"original_max_position_embeddings\": 8192,\n",
              "    \"rope_type\": \"llama3\"\n",
              "  },\n",
              "  \"rope_theta\": 500000.0,\n",
              "  \"tie_word_embeddings\": true,\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.51.3\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 128256\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining HookedTransfromer from TransformerLens for SkipLayer Llama and derived Assistant Model"
      ],
      "metadata": {
        "id": "sj3ImB1Akd9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_grad_enabled(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpUj999EcScz",
        "outputId": "6e1e1f3d-7fa8-45e7-8120-6aa78ebfd57c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7db83ec46a50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assitantModel.device\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj0NYxTCvENJ",
        "outputId": "8341849f-0703-4a1e-b28e-a9c1006bbd36"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llama_model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "model = HookedTransformer.from_pretrained(llama_model_name, hf_model = assitantModel, device=device, hf_token = hf_token, first_n_layers = earlyExitLayer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "d9bb7a05184147939f156abd55718b20",
            "3cc41754db444938a07847585637fa21",
            "e60eae335a11426da67d59fb2d7ca9d4",
            "beda5ece15794e82897856c9b944211f",
            "e7dd73ea3daf41d799eb2d8553643c7d",
            "a7f7eb0b4c9541f7b2a6817435b403ff",
            "af5e365bd15f4df6bdca43782361640a",
            "5290e416450041dca931ecb4486f3e60",
            "bc1f364a3b2446f38b62efcbf8b956f3",
            "7ec10849e375436fad5070a0309a3eab",
            "064d683432e148b1a943300940c6c971",
            "a607ea3a66994eaf9adcd77f0e89a9d2",
            "b2fe60b55efd4408b6ef3f1d426e3742",
            "32c9f3345ea942ce987a2812197fbfa8",
            "9252d5dbb79b4f9fb3a8706b7306c988",
            "df0ab7d610fa42498773d5f65ac7f599",
            "767b53ba64f34fc39e4815480c3eba11",
            "160ed651b6d8425397932fd9a53fd91b",
            "62a02f1dfe4d45be9febf6634ed50185",
            "e46a1ae6b5a5424780e84376e4176546",
            "3ae3f57f2cb94d54a5f922fb1a628f51",
            "a73acd6cb9164250a9ebb61f7c7518f2",
            "582b84838ce04858aa4ba8cac204097c",
            "6d021801d16d49aba78a36af8d9501e8",
            "a0ba239b8a1e46bdb9afcd7a746035df",
            "d042a7cf63c44e8e852629fa66d7ea7e",
            "065d0ec3db044e96ad32d6637b4ccffe",
            "615975f3f77a40c18587d6dad5951354",
            "b50701da72b54696bfb212a3ec9476e8",
            "856e9581a2e548b3a5e2c5504020a27f",
            "b4a4c08ec94d42f4bdde5a554efd02ed",
            "434f8dfae716433193f1b5585faedb46",
            "11edb704b71d4b37a357e3e0f902d04b"
          ]
        },
        "id": "iA_UGC6Pchp4",
        "outputId": "61264720-babf-4080-c371-803713d2e0dd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9bb7a05184147939f156abd55718b20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a607ea3a66994eaf9adcd77f0e89a9d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "582b84838ce04858aa4ba8cac204097c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model meta-llama/Llama-3.2-1B into HookedTransformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNM3ODvyxgBP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rw85_dPhxji5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_description_text = \"\"\"## Loading Models\n",
        "\n",
        "HookedTransformer comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. See my explainer for documentation of all supported models, and this table for hyper-parameters and the name used to load them. Each model is loaded into the consistent HookedTransformer architecture, designed to be clean, consistent and interpretability-friendly.\n",
        "\n",
        "For this demo notebook we'll look at GPT-2 Small, an 80M parameter model. To try the model the model out, let's find the loss on this paragraph!\"\"\"\n",
        "loss = model(model_description_text, return_type=\"loss\")\n",
        "print(\"Model loss:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvqgDPHRchzK",
        "outputId": "fe6a2e7c-e832-45d8-c2b7-3dd7bcc9b875"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loss: tensor(3.4780, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate(model_description_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "945325b3e88442fc963388e242bdc87f",
            "8eccf66d6e64426ca7ee1ad85b1725c9",
            "e4297bd2ad734d25a09e93f7a398807b",
            "2eb41da80d374d63a62a1adbf46d7715",
            "899279136fd141259b57492aca2b12c5",
            "3790311426ad492fb31f111be4a0cde6",
            "8f34749fbf844cd59cfab3135f15a4ab",
            "3a97a206328b4310823a7c25ab49ffb5",
            "8be7fbe2929e4ea6bc979038c4fa8407",
            "23fa9088f17046c4a185f8e05ae97d9a",
            "5043b973ed0e4aaab12aff664c4f78f1"
          ]
        },
        "id": "3aZjf2EpcSgg",
        "outputId": "437f4c05-3b9c-4c7c-fba8-92225d1ce269"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "945325b3e88442fc963388e242bdc87f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"## Loading Models\\n\\nHookedTransformer comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. See my explainer for documentation of all supported models, and this table for hyper-parameters and the name used to load them. Each model is loaded into the consistent HookedTransformer architecture, designed to be clean, consistent and interpretability-friendly.\\n\\nFor this demo notebook we'll look at GPT-2 Small, an 80M parameter model. To try the model the model out, let's find the loss on this paragraph! We'll save that to out_loss later. \\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TAfHUOz-jPIA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "68opa_YYjRAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Direct Logit Attribution\n"
      ],
      "metadata": {
        "id": "hU7vs_NsjRK1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cjyKp40GjPdR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ui6qwPSvcSjo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Direct Logit Attribution Experiment Implementation"
      ],
      "metadata": {
        "id": "gBqZLDpuDCf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuration\n",
        "sampleSentence = \"The capital city of France is\""
      ],
      "metadata": {
        "id": "I_nIJ3T6DUWQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = model.to_tokens(sampleSentence, prepend_bos = True).to(device)"
      ],
      "metadata": {
        "id": "un2KzD4CITvz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmwNjgckIiB0",
        "outputId": "ecdb8fc4-0177-4a52-9719-44173193109e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[128000,    791,   6864,   3363,    315,   9822,    374]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(tokens)\n",
        "torch.argmax(out, axis = -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUVw_Uimy7iG",
        "outputId": "d6730524-9d22-40a1-b198-7f37029fb4bd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2,   220,   315,   315,   279,    11, 12366]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_logits, cache = model.run_with_cache(tokens)"
      ],
      "metadata": {
        "id": "BeBLJY4ulVJR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhuakP9jltM0",
        "outputId": "055864bb-86cc-4988-d231-91bd5d9ae45f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ActivationCache with keys ['hook_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_rot_q', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_pre_linear', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_rot_q', 'blocks.1.attn.hook_rot_k', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_pre_linear', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_rot_q', 'blocks.2.attn.hook_rot_k', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_pre_linear', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_rot_q', 'blocks.3.attn.hook_rot_k', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_pre_linear', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_rot_q', 'blocks.4.attn.hook_rot_k', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_pre_linear', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_rot_q', 'blocks.5.attn.hook_rot_k', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_pre_linear', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_rot_q', 'blocks.6.attn.hook_rot_k', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_pre_linear', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_rot_q', 'blocks.7.attn.hook_rot_k', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_pre_linear', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_rot_q', 'blocks.8.attn.hook_rot_k', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_pre_linear', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_rot_q', 'blocks.9.attn.hook_rot_k', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_pre_linear', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_rot_q', 'blocks.10.attn.hook_rot_k', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_pre_linear', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_rot_q', 'blocks.11.attn.hook_rot_k', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_pre_linear', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'blocks.12.hook_resid_pre', 'blocks.12.ln1.hook_scale', 'blocks.12.ln1.hook_normalized', 'blocks.12.attn.hook_q', 'blocks.12.attn.hook_k', 'blocks.12.attn.hook_v', 'blocks.12.attn.hook_rot_q', 'blocks.12.attn.hook_rot_k', 'blocks.12.attn.hook_attn_scores', 'blocks.12.attn.hook_pattern', 'blocks.12.attn.hook_z', 'blocks.12.hook_attn_out', 'blocks.12.hook_resid_mid', 'blocks.12.ln2.hook_scale', 'blocks.12.ln2.hook_normalized', 'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_pre_linear', 'blocks.12.mlp.hook_post', 'blocks.12.hook_mlp_out', 'blocks.12.hook_resid_post', 'blocks.13.hook_resid_pre', 'blocks.13.ln1.hook_scale', 'blocks.13.ln1.hook_normalized', 'blocks.13.attn.hook_q', 'blocks.13.attn.hook_k', 'blocks.13.attn.hook_v', 'blocks.13.attn.hook_rot_q', 'blocks.13.attn.hook_rot_k', 'blocks.13.attn.hook_attn_scores', 'blocks.13.attn.hook_pattern', 'blocks.13.attn.hook_z', 'blocks.13.hook_attn_out', 'blocks.13.hook_resid_mid', 'blocks.13.ln2.hook_scale', 'blocks.13.ln2.hook_normalized', 'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_pre_linear', 'blocks.13.mlp.hook_post', 'blocks.13.hook_mlp_out', 'blocks.13.hook_resid_post', 'blocks.14.hook_resid_pre', 'blocks.14.ln1.hook_scale', 'blocks.14.ln1.hook_normalized', 'blocks.14.attn.hook_q', 'blocks.14.attn.hook_k', 'blocks.14.attn.hook_v', 'blocks.14.attn.hook_rot_q', 'blocks.14.attn.hook_rot_k', 'blocks.14.attn.hook_attn_scores', 'blocks.14.attn.hook_pattern', 'blocks.14.attn.hook_z', 'blocks.14.hook_attn_out', 'blocks.14.hook_resid_mid', 'blocks.14.ln2.hook_scale', 'blocks.14.ln2.hook_normalized', 'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_pre_linear', 'blocks.14.mlp.hook_post', 'blocks.14.hook_mlp_out', 'blocks.14.hook_resid_post', 'blocks.15.hook_resid_pre', 'blocks.15.ln1.hook_scale', 'blocks.15.ln1.hook_normalized', 'blocks.15.attn.hook_q', 'blocks.15.attn.hook_k', 'blocks.15.attn.hook_v', 'blocks.15.attn.hook_rot_q', 'blocks.15.attn.hook_rot_k', 'blocks.15.attn.hook_attn_scores', 'blocks.15.attn.hook_pattern', 'blocks.15.attn.hook_z', 'blocks.15.hook_attn_out', 'blocks.15.hook_resid_mid', 'blocks.15.ln2.hook_scale', 'blocks.15.ln2.hook_normalized', 'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_pre_linear', 'blocks.15.mlp.hook_post', 'blocks.15.hook_mlp_out', 'blocks.15.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex_p9pqiltPa",
        "outputId": "64822029-6eb9-4f50-f457-aa28a6638cf5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 128256])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate(sampleSentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "871450e3c2f24bc5a3d781e51d247e67",
            "90128cbe40f242b88547f7466c13f22d",
            "f09cb21e8f2b49008efbde163707470d",
            "f15ef474efdd4dc1baa8b1ebea535f9e",
            "eaa7db903ef04e1ba081d3d189a87026",
            "0316f828ee654458937e7b1fcdaffed0",
            "18dc2e55586845068137c92f8355ee4f",
            "1769d73328fb4971b0a72c7f20c996f1",
            "85910e0dfc4d405889f1233a447483db",
            "fb49b009f5c643c5afaf1b6c34060438",
            "c33140f6f1d444799c65c16d74ce37a0"
          ]
        },
        "id": "mAHbYRraltSt",
        "outputId": "661115e2-ceea-4780-82d2-75e7d7bf5217"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "871450e3c2f24bc5a3d781e51d247e67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital city of France is a modest stop for anyone taking a trip to the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate(\"What is the capital city of France?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "102a95b75adf4274a9c003fe96f59fb8",
            "84262af0802f4cdaabb5aeaa1174d408",
            "ef71ae9569424b368d54fccacd52ae91",
            "ee6c3f2362b44c1db8f2c32a8e5db80e",
            "851c2b8b8315414aa1f014ee40cfbd56",
            "d7108cbf1be74fb4a42106752250a2c5",
            "5d9c094532bd425ab57f21f5c9459bae",
            "5f2ebab7155144ab962975165c09de29",
            "b2c3195f39e14cf59f50ea7a82356d81",
            "8b5d58af7bcb486491cd053eed5af15f",
            "5ec198e809514e24a07427a6b619c8db"
          ]
        },
        "id": "IK09bUFtltWS",
        "outputId": "7d778e73-ba05-4f7f-9cf0-21ca634b822a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "102a95b75adf4274a9c003fe96f59fb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the capital city of France? in Plucky Sayings\\nList of all popular'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerExperiment:\n",
        "   def __init__(self, model_id) -> None:\n",
        "       self.model_id = model_id\n",
        "       self.model = None\n",
        "       self.tokenizer = None\n",
        "       self.logit_contributions_per_layer = []\n",
        "\n",
        "\n",
        "\n",
        "   def deriveAssistantModel(model : torch.nn.Module, earlyExitLayer : int, deallocateSrcModelFlag : bool = False):\n",
        "        generationConfig = model.generation_config\n",
        "        weightsMemory = {id(w): w for w in model.parameters()}\n",
        "        assistantModel = deepcopy(model, memo = weightsMemory) # Clone main model with shared weights\n",
        "        assistantModel.model.layers = assistantModel.model.layers[:earlyExitLayer] # Apply early exit\n",
        "        del assistantModel.model.layers[earlyExitLayer:]\n",
        "        assistantModel.generation_config = generationConfig\n",
        "        return assistantModel\n",
        "\n",
        "   def setModel(self, model : torch.nn.Module):\n",
        "       self.model = model\n",
        "\n",
        "   def get_layer_logit_contributions(model: HookedTransformer, input_tokens: torch.Tensor, final_predicted_token_id: int):\n",
        "      \"\"\"\n",
        "      Calculates the direct logit contribution of each layer to the logits of the\n",
        "      token predicted in the final layer.\n",
        "\n",
        "      Args:\n",
        "          model: The HookedTransformer model.\n",
        "          input_tokens: The input tokens (shape: [batch, seq_len]).\n",
        "          final_predicted_token_id: The ID of the token predicted by the final layer.\n",
        "\n",
        "      Returns:\n",
        "          A dictionary where keys are layer indices and values are the logit contribution\n",
        "          of that layer to the final predicted token.\n",
        "      \"\"\"\n",
        "      layer_contributions = {}\n",
        "\n",
        "      def hook_fn(hook, layern):\n",
        "          layer_output = hook.output\n",
        "\n",
        "          if 'mlp' in hook.name:\n",
        "              layer_logits = model.unembed(layer_output)\n",
        "          elif 'attn' in hook.name:\n",
        "              layer_logits = model.unembed(layer_output)\n",
        "          else:\n",
        "              return\n",
        "\n",
        "          # Contribution to the logits of the final predicted token\n",
        "          contribution = layer_logits[0, -1, final_predicted_token_id].item()\n",
        "          return contribution\n",
        "\n",
        "      for layer_idx in range(model.cfg.n_layers):\n",
        "          hook_name_attn = f\"blocks.{layer_idx}.attn.hook_result\"\n",
        "          hook_name_mlp = f\"blocks.{layer_idx}.mlp.hook_post\"\n",
        "\n",
        "          # Capture contribution from attention output\n",
        "          attn_contribution = model.run_hook(input_tokens, hook_name_attn, hook_fn, layern=layer_idx)\n",
        "          if attn_contribution is not None:\n",
        "              layer_contributions[f\"layer_{layer_idx}_attn\"] = attn_contribution\n",
        "\n",
        "          # Capture contribution from MLP output\n",
        "          mlp_contribution = model.run_hook(input_tokens, hook_name_mlp, hook_fn, layern=layer_idx)\n",
        "          if mlp_contribution is not None:\n",
        "             layer_contributions[f\"layer_{layer_idx}_mlp\"] = mlp_contribution\n",
        "\n",
        "          return layer_contributions"
      ],
      "metadata": {
        "id": "GQgriQU79iYn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8r3IVid_JbT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpFgAJd5CVvu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformer_lens import HookedTransformer\n",
        "from torch.nn.functional import log_softmax\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration (same as before)\n",
        "MODEL_NAME = llama_model_name  # Replace with the correct Llama-3.2-1B identifier if available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "INPUT_TEXT = \"The capital of France is\"\n",
        "MAX_NEW_TOKENS = 10\n",
        "\n",
        "try:\n",
        "    model = HookedTransformer.from_pretrained(MODEL_NAME, hf_model = model_modified).to(DEVICE)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model {MODEL_NAME}: {e}\")\n",
        "    exit()\n",
        "\n",
        "tokenizer = model.tokenizer\n",
        "tokens = tokenizer.encode(INPUT_TEXT, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "def calculate_log_prob_increase(model: HookedTransformer, input_tokens: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Calculates the log probability of the final predicted token at the output\n",
        "    of each layer and the increase compared to the previous layer.\n",
        "    \"\"\"\n",
        "    logits, cache = model.run_with_cache(input_tokens)\n",
        "    final_predicted_token_id = torch.argmax(logits[0, -1, :]).item()\n",
        "\n",
        "    layer_log_probs = {}\n",
        "    log_prob_increases = {}\n",
        "    previous_log_prob = None\n",
        "\n",
        "    for layer_idx in range(model.cfg.n_layers):\n",
        "        hook_name = f\"blocks.{layer_idx}.hook_resid_post\"\n",
        "        layer_output = cache[hook_name]\n",
        "        layer_logits = model.unembed(layer_output)\n",
        "        current_log_prob = log_softmax(layer_logits[0, -1, :], dim=-1)[final_predicted_token_id].item()\n",
        "        layer_log_probs[f\"layer_{layer_idx}\"] = current_log_prob\n",
        "\n",
        "        if previous_log_prob is not None:\n",
        "            increase = current_log_prob - previous_log_prob\n",
        "            log_prob_increases[f\"layer_{layer_idx}\"] = increase\n",
        "        else:\n",
        "            log_prob_increases[f\"layer_{layer_idx}\"] = 0.0  # No increase for the first layer\n",
        "\n",
        "        previous_log_prob = current_log_prob\n",
        "\n",
        "    # Calculate increase from embedding layer (approximation)\n",
        "    embed_output = cache['hook_embed'] # + cache['pos_embed']\n",
        "    embed_logits = model.unembed(embed_output)\n",
        "    embed_log_prob = log_softmax(embed_logits[0, -1, :], dim=-1)[final_predicted_token_id].item()\n",
        "    log_prob_increases['embedding'] = layer_log_probs['layer_0'] - embed_log_prob\n",
        "\n",
        "    return layer_log_probs, log_prob_increases\n",
        "\n",
        "# Generate and analyze\n",
        "for step in range(MAX_NEW_TOKENS): # For simplicity, just analyze the first prediction\n",
        "    logits, cache = model.run_with_cache(tokens, remove_batch_dim=True)\n",
        "    final_predicted_token_id = torch.argmax(logits[:, -1, :], dim=-1).item()\n",
        "    print(\"Input:\", tokenizer.decode(tokens[0]))\n",
        "    print(\"Final Predicted Token:\", tokenizer.decode([final_predicted_token_id]))\n",
        "\n",
        "    layer_log_probs, log_prob_increases = calculate_log_prob_increase(model, tokens)\n",
        "\n",
        "    df_log_probs = pd.DataFrame([layer_log_probs])\n",
        "    print(\"\\nLog Probability of the Final Predicted Token at Each Layer:\")\n",
        "    print(df_log_probs.T)\n",
        "\n",
        "    df_increases = pd.DataFrame([log_prob_increases])\n",
        "    print(\"\\nLog Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\")\n",
        "    print(df_increases.T)\n",
        "\n",
        "    tokens = torch.cat((tokens, torch.tensor([[final_predicted_token_id]]).to(DEVICE)), dim=-1)\n",
        "\n",
        "# Optional Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if 'df_increases' in locals() and not df_increases.empty:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    df_increases.T.plot(kind='bar', legend=False)\n",
        "    plt.title('Log Probability Increase of Final Predicted Token at Each Layer')\n",
        "    plt.xlabel('Transformer Layer (including Embedding)')\n",
        "    plt.ylabel('Log Probability Increase')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ELxYP1X0Ku6f",
        "outputId": "0adaae92-9b3f-4191-cc8d-6121c93a0748"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model meta-llama/Llama-3.2-1B into HookedTransformer\n",
            "Moving model to device:  cuda\n",
            "Input: <|begin_of_text|>The capital of France is\n",
            "Final Predicted Token:  Paris\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -11.425403\n",
            "layer_1  -11.288629\n",
            "layer_2  -11.061173\n",
            "layer_3  -10.225573\n",
            "layer_4   -9.544531\n",
            "layer_5   -9.623109\n",
            "layer_6   -9.212948\n",
            "layer_7   -8.767255\n",
            "layer_8   -7.833096\n",
            "layer_9   -6.736149\n",
            "layer_10  -5.178202\n",
            "layer_11  -3.120447\n",
            "layer_12  -1.852006\n",
            "layer_13  -1.252159\n",
            "layer_14  -1.211358\n",
            "layer_15  -0.959855\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.136774\n",
            "layer_2    0.227455\n",
            "layer_3    0.835601\n",
            "layer_4    0.681042\n",
            "layer_5   -0.078578\n",
            "layer_6    0.410161\n",
            "layer_7    0.445693\n",
            "layer_8    0.934159\n",
            "layer_9    1.096947\n",
            "layer_10   1.557948\n",
            "layer_11   2.057754\n",
            "layer_12   1.268441\n",
            "layer_13   0.599848\n",
            "layer_14   0.040801\n",
            "layer_15   0.251502\n",
            "embedding -0.046429\n",
            "Input: <|begin_of_text|>The capital of France is Paris\n",
            "Final Predicted Token: .\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -10.957176\n",
            "layer_1  -10.336303\n",
            "layer_2   -9.703217\n",
            "layer_3   -9.127653\n",
            "layer_4   -8.340539\n",
            "layer_5   -7.672990\n",
            "layer_6   -7.026233\n",
            "layer_7   -6.403550\n",
            "layer_8   -5.604827\n",
            "layer_9   -4.419920\n",
            "layer_10  -3.403870\n",
            "layer_11  -2.398916\n",
            "layer_12  -1.514663\n",
            "layer_13  -1.272625\n",
            "layer_14  -1.029464\n",
            "layer_15  -0.864834\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.620873\n",
            "layer_2    0.633086\n",
            "layer_3    0.575563\n",
            "layer_4    0.787114\n",
            "layer_5    0.667549\n",
            "layer_6    0.646758\n",
            "layer_7    0.622683\n",
            "layer_8    0.798723\n",
            "layer_9    1.184907\n",
            "layer_10   1.016050\n",
            "layer_11   1.004955\n",
            "layer_12   0.884253\n",
            "layer_13   0.242037\n",
            "layer_14   0.243161\n",
            "layer_15   0.164629\n",
            "embedding  0.832197\n",
            "Input: <|begin_of_text|>The capital of France is Paris.\n",
            "Final Predicted Token:  It\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -11.259054\n",
            "layer_1  -10.796367\n",
            "layer_2  -10.292894\n",
            "layer_3   -9.654178\n",
            "layer_4   -9.258432\n",
            "layer_5   -8.931369\n",
            "layer_6   -8.262349\n",
            "layer_7   -7.890399\n",
            "layer_8   -6.904543\n",
            "layer_9   -5.895257\n",
            "layer_10  -4.350237\n",
            "layer_11  -3.109259\n",
            "layer_12  -2.153447\n",
            "layer_13  -1.671260\n",
            "layer_14  -1.266374\n",
            "layer_15  -1.126550\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.462687\n",
            "layer_2    0.503472\n",
            "layer_3    0.638717\n",
            "layer_4    0.395745\n",
            "layer_5    0.327064\n",
            "layer_6    0.669020\n",
            "layer_7    0.371950\n",
            "layer_8    0.985856\n",
            "layer_9    1.009286\n",
            "layer_10   1.545020\n",
            "layer_11   1.240978\n",
            "layer_12   0.955812\n",
            "layer_13   0.482187\n",
            "layer_14   0.404887\n",
            "layer_15   0.139824\n",
            "embedding -0.526184\n",
            "Input: <|begin_of_text|>The capital of France is Paris. It\n",
            "Final Predicted Token:  is\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -10.832293\n",
            "layer_1  -10.452743\n",
            "layer_2   -9.851847\n",
            "layer_3   -9.201438\n",
            "layer_4   -8.604944\n",
            "layer_5   -8.232925\n",
            "layer_6   -7.468642\n",
            "layer_7   -7.013423\n",
            "layer_8   -5.988113\n",
            "layer_9   -4.506405\n",
            "layer_10  -3.094462\n",
            "layer_11  -1.690860\n",
            "layer_12  -0.934911\n",
            "layer_13  -0.615909\n",
            "layer_14  -0.434043\n",
            "layer_15  -0.290522\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.379550\n",
            "layer_2    0.600896\n",
            "layer_3    0.650409\n",
            "layer_4    0.596494\n",
            "layer_5    0.372019\n",
            "layer_6    0.764283\n",
            "layer_7    0.455219\n",
            "layer_8    1.025311\n",
            "layer_9    1.481708\n",
            "layer_10   1.411943\n",
            "layer_11   1.403602\n",
            "layer_12   0.755949\n",
            "layer_13   0.319002\n",
            "layer_14   0.181866\n",
            "layer_15   0.143521\n",
            "embedding  0.323866\n",
            "Input: <|begin_of_text|>The capital of France is Paris. It is\n",
            "Final Predicted Token:  the\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -11.029123\n",
            "layer_1  -10.552508\n",
            "layer_2  -10.016663\n",
            "layer_3   -9.304136\n",
            "layer_4   -8.880172\n",
            "layer_5   -8.500009\n",
            "layer_6   -7.974366\n",
            "layer_7   -7.460755\n",
            "layer_8   -6.360883\n",
            "layer_9   -5.294428\n",
            "layer_10  -4.063455\n",
            "layer_11  -2.983833\n",
            "layer_12  -1.920950\n",
            "layer_13  -1.609550\n",
            "layer_14  -1.361188\n",
            "layer_15  -1.198188\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.476615\n",
            "layer_2    0.535846\n",
            "layer_3    0.712526\n",
            "layer_4    0.423965\n",
            "layer_5    0.380163\n",
            "layer_6    0.525642\n",
            "layer_7    0.513611\n",
            "layer_8    1.099872\n",
            "layer_9    1.066455\n",
            "layer_10   1.230973\n",
            "layer_11   1.079623\n",
            "layer_12   1.062883\n",
            "layer_13   0.311400\n",
            "layer_14   0.248362\n",
            "layer_15   0.163000\n",
            "embedding -0.529023\n",
            "Input: <|begin_of_text|>The capital of France is Paris. It is the\n",
            "Final Predicted Token:  most\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -11.114631\n",
            "layer_1  -10.693336\n",
            "layer_2  -10.143201\n",
            "layer_3   -9.576944\n",
            "layer_4   -9.008749\n",
            "layer_5   -8.791928\n",
            "layer_6   -8.245022\n",
            "layer_7   -7.934368\n",
            "layer_8   -6.921719\n",
            "layer_9   -5.972754\n",
            "layer_10  -4.795368\n",
            "layer_11  -3.081179\n",
            "layer_12  -2.244139\n",
            "layer_13  -2.011409\n",
            "layer_14  -1.616661\n",
            "layer_15  -1.496814\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.421295\n",
            "layer_2    0.550135\n",
            "layer_3    0.566257\n",
            "layer_4    0.568195\n",
            "layer_5    0.216821\n",
            "layer_6    0.546906\n",
            "layer_7    0.310654\n",
            "layer_8    1.012649\n",
            "layer_9    0.948965\n",
            "layer_10   1.177386\n",
            "layer_11   1.714189\n",
            "layer_12   0.837041\n",
            "layer_13   0.232730\n",
            "layer_14   0.394748\n",
            "layer_15   0.119848\n",
            "embedding -0.390928\n",
            "Input: <|begin_of_text|>The capital of France is Paris. It is the most\n",
            "Final Predicted Token:  visited\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -11.232569\n",
            "layer_1  -10.751634\n",
            "layer_2  -10.188606\n",
            "layer_3   -9.718506\n",
            "layer_4   -9.266115\n",
            "layer_5   -8.898628\n",
            "layer_6   -8.602861\n",
            "layer_7   -7.852922\n",
            "layer_8   -7.091156\n",
            "layer_9   -6.028304\n",
            "layer_10  -5.041075\n",
            "layer_11  -3.693357\n",
            "layer_12  -2.783484\n",
            "layer_13  -2.130705\n",
            "layer_14  -1.699140\n",
            "layer_15  -1.393373\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.480935\n",
            "layer_2    0.563027\n",
            "layer_3    0.470100\n",
            "layer_4    0.452391\n",
            "layer_5    0.367487\n",
            "layer_6    0.295767\n",
            "layer_7    0.749939\n",
            "layer_8    0.761766\n",
            "layer_9    1.062853\n",
            "layer_10   0.987228\n",
            "layer_11   1.347718\n",
            "layer_12   0.909873\n",
            "layer_13   0.652778\n",
            "layer_14   0.431565\n",
            "layer_15   0.305767\n",
            "embedding  0.351003\n",
            "Input: <|begin_of_text|>The capital of France is Paris. It is the most visited\n",
            "Final Predicted Token:  city\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -11.253301\n",
            "layer_1  -10.553429\n",
            "layer_2   -9.852113\n",
            "layer_3   -8.990007\n",
            "layer_4   -8.192046\n",
            "layer_5   -7.793019\n",
            "layer_6   -7.328398\n",
            "layer_7   -6.871866\n",
            "layer_8   -6.173099\n",
            "layer_9   -4.937192\n",
            "layer_10  -3.657208\n",
            "layer_11  -2.333539\n",
            "layer_12  -1.411395\n",
            "layer_13  -0.797926\n",
            "layer_14  -0.416363\n",
            "layer_15  -0.273368\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.699872\n",
            "layer_2    0.701316\n",
            "layer_3    0.862105\n",
            "layer_4    0.797961\n",
            "layer_5    0.399027\n",
            "layer_6    0.464621\n",
            "layer_7    0.456532\n",
            "layer_8    0.698767\n",
            "layer_9    1.235907\n",
            "layer_10   1.279984\n",
            "layer_11   1.323669\n",
            "layer_12   0.922144\n",
            "layer_13   0.613469\n",
            "layer_14   0.381563\n",
            "layer_15   0.142995\n",
            "embedding  0.550210\n",
            "Input: <|begin_of_text|>The capital of France is Paris. It is the most visited city\n",
            "Final Predicted Token:  in\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -10.852977\n",
            "layer_1  -10.059832\n",
            "layer_2   -9.322074\n",
            "layer_3   -8.533542\n",
            "layer_4   -8.093693\n",
            "layer_5   -7.639524\n",
            "layer_6   -7.048948\n",
            "layer_7   -6.648708\n",
            "layer_8   -5.860994\n",
            "layer_9   -4.111449\n",
            "layer_10  -2.681864\n",
            "layer_11  -1.333230\n",
            "layer_12  -0.617516\n",
            "layer_13  -0.246704\n",
            "layer_14  -0.214959\n",
            "layer_15  -0.137618\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.793145\n",
            "layer_2    0.737758\n",
            "layer_3    0.788532\n",
            "layer_4    0.439849\n",
            "layer_5    0.454169\n",
            "layer_6    0.590576\n",
            "layer_7    0.400239\n",
            "layer_8    0.787714\n",
            "layer_9    1.749545\n",
            "layer_10   1.429585\n",
            "layer_11   1.348634\n",
            "layer_12   0.715714\n",
            "layer_13   0.370812\n",
            "layer_14   0.031745\n",
            "layer_15   0.077341\n",
            "embedding  0.720461\n",
            "Input: <|begin_of_text|>The capital of France is Paris. It is the most visited city in\n",
            "Final Predicted Token:  the\n",
            "\n",
            "Log Probability of the Final Predicted Token at Each Layer:\n",
            "                  0\n",
            "layer_0  -10.982111\n",
            "layer_1  -10.249526\n",
            "layer_2   -9.797501\n",
            "layer_3   -8.895498\n",
            "layer_4   -8.450880\n",
            "layer_5   -7.935441\n",
            "layer_6   -7.549854\n",
            "layer_7   -7.029121\n",
            "layer_8   -5.962710\n",
            "layer_9   -4.547970\n",
            "layer_10  -2.941491\n",
            "layer_11  -1.482664\n",
            "layer_12  -0.720183\n",
            "layer_13  -0.517175\n",
            "layer_14  -0.285927\n",
            "layer_15  -0.247796\n",
            "\n",
            "Log Probability Increase of the Final Predicted Token at Each Layer (vs. Previous Layer/Embedding):\n",
            "                  0\n",
            "layer_0    0.000000\n",
            "layer_1    0.732585\n",
            "layer_2    0.452025\n",
            "layer_3    0.902002\n",
            "layer_4    0.444618\n",
            "layer_5    0.515439\n",
            "layer_6    0.385587\n",
            "layer_7    0.520733\n",
            "layer_8    1.066411\n",
            "layer_9    1.414741\n",
            "layer_10   1.606478\n",
            "layer_11   1.458828\n",
            "layer_12   0.762480\n",
            "layer_13   0.203008\n",
            "layer_14   0.231248\n",
            "layer_15   0.038132\n",
            "embedding -0.972661\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformer_lens import HookedTransformer\n",
        "from torch.nn.functional import log_softmax\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np # Added for cumulative sum\n",
        "\n",
        "class TransformerExperiment:\n",
        "    \"\"\"\n",
        "    A class to experiment with Transformer models using TransformerLens,\n",
        "    focusing on analyzing the log probability contributions of different\n",
        "    model components (embedding, attention blocks, MLP blocks) to the\n",
        "    predicted token.\n",
        "    \"\"\"\n",
        "    def __init__(self, modelId: str, hfToken: str = None, preloadedModelId: str = None) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the experiment by loading the specified model and tokenizer.\n",
        "\n",
        "        Args:\n",
        "            modelId (str): The Hugging Face model ID to load with TransformerLens (e.g., \"gpt2\", \"EleutherAI/pythia-70m\").\n",
        "                           This model will be used for the analysis.\n",
        "            hfToken (str, optional): Hugging Face API token. If None, attempts to use\n",
        "                                     the HUGGINGFACE_TOKEN environment variable or relies on\n",
        "                                     CLI login/cached credentials. Defaults to None.\n",
        "            preloadedModelId (str, optional): If specified, preloads this model ID using the standard\n",
        "                                              Hugging Face Transformers library first. This is useful\n",
        "                                              for models not directly supported by TransformerLens'\n",
        "                                              from_pretrained or requiring specific configurations\n",
        "                                              (like gated models such as Llama). The preloaded\n",
        "                                              hf_model is then passed to HookedTransformer.\n",
        "                                              Defaults to None.\n",
        "        \"\"\"\n",
        "        self.modelId = modelId\n",
        "        self.model: HookedTransformer = None\n",
        "        self.tokenizer: AutoTokenizer = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        self.logitContributionsPerToken: list[dict[int, float]] = [] # Stores contributions for individual predictions\n",
        "        self.llmModel: AutoModelForCausalLM = None # Stores the preloaded HF model if used\n",
        "\n",
        "        # --- Token Handling ---\n",
        "        if hfToken is None and 'HUGGINGFACE_TOKEN' in os.environ:\n",
        "            hfToken = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "            print(\"Using Hugging Face token from environment variable.\")\n",
        "        elif hfToken:\n",
        "            print(\"Using Hugging Face token provided directly.\")\n",
        "        else:\n",
        "            print(\"Attempting to load model without explicit token (relies on CLI login or cached credentials).\")\n",
        "            # Set token to None explicitly if not found, for clarity in from_pretrained calls\n",
        "            hfToken = None\n",
        "\n",
        "        # --- Model Loading ---\n",
        "        if preloadedModelId:\n",
        "            self._preloadLlm(preloadedModelId, hfToken)\n",
        "            try:\n",
        "                print(f\"Loading HookedTransformer wrapping preloaded model: {preloadedModelId}\")\n",
        "                # Pass the token here as well, TransformerLens might need it for config etc.\n",
        "                self.model = HookedTransformer.from_pretrained(\n",
        "                    modelId, # Use the ID TransformerLens expects, even if wrapping\n",
        "                    hf_model=self.llmModel,\n",
        "                    device=self.device, # Explicitly set device\n",
        "                    fold_ln=False, # Often needed for accurate cache usage with HF models\n",
        "                    fold_value_biases=False,\n",
        "                    center_writing_weights=False,\n",
        "                    center_unembed=False,\n",
        "                    tokenizer=self.tokenizer, # Pass preloaded tokenizer\n",
        "                    # token=hfToken # Pass token if needed by TLens' internal logic for this model ID\n",
        "                ).to(self.device) # Ensure final model is on correct device\n",
        "                # self.tokenizer is already set during _preloadLlm\n",
        "                print(\"HookedTransformer loaded successfully wrapping preloaded model.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading HookedTransformer from preloaded model {preloadedModelId}: {e}\")\n",
        "                print(\"Falling back to default loading mechanism for modelId:\", self.modelId)\n",
        "                self._loadModel(hfToken) # Fallback to default loading using self.modelId\n",
        "        else:\n",
        "            self._loadModel(hfToken)\n",
        "\n",
        "        # Final check\n",
        "        if self.model is None or self.tokenizer is None:\n",
        "             raise RuntimeError(\"Failed to load model and tokenizer.\")\n",
        "        print(f\"Model '{self.model.cfg.model_name}' loaded with {self.model.cfg.n_layers} layers.\")\n",
        "\n",
        "\n",
        "    def _loadModel(self, hfToken: str):\n",
        "        \"\"\"Loads the model directly using HookedTransformer.from_pretrained.\"\"\"\n",
        "        print(f\"Loading model '{self.modelId}' directly with TransformerLens...\")\n",
        "        try:\n",
        "            # Explicitly pass device and token\n",
        "            self.model = HookedTransformer.from_pretrained(\n",
        "                self.modelId,\n",
        "                device=self.device,\n",
        "                token=hfToken\n",
        "            ).to(self.device) # Ensure it's on the correct device\n",
        "            self.tokenizer = self.model.tokenizer # Get tokenizer from HookedTransformer\n",
        "            print(f\"Model '{self.modelId}' loaded successfully via TransformerLens.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.modelId} directly with TransformerLens: {e}\")\n",
        "            print(\"Check model name, internet connection, and HF credentials/access.\")\n",
        "            raise\n",
        "\n",
        "    def _preloadLlm(self, preloadedModelId: str, hfToken: str):\n",
        "        \"\"\"Preloads the LLM using Hugging Face's AutoModelForCausalLM.\"\"\"\n",
        "        print(f\"--- Pre-loading Hugging Face Model: {preloadedModelId} ---\")\n",
        "        print(f\"Pre-loading tokenizer for model: {preloadedModelId}\")\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(preloadedModelId, token=hfToken)\n",
        "            print(\"Tokenizer pre-loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error pre-loading tokenizer: {e}\")\n",
        "            print(f\"Please ensure you have requested and been granted access to the model on Hugging Face: https://huggingface.co/{preloadedModelId}\")\n",
        "            print(\"And that you are properly authenticated (e.g., via `huggingface-cli login` or providing a token).\")\n",
        "            exit(1) # Exit if tokenizer fails, as model loading will likely fail too\n",
        "\n",
        "        print(f\"Pre-loading model: {preloadedModelId}\")\n",
        "        print(\"This may take a while and require significant RAM/VRAM...\")\n",
        "\n",
        "        try:\n",
        "            # Use device_map=\"auto\" for efficient loading across devices if available\n",
        "            # Requires 'accelerate' library: pip install accelerate\n",
        "            self.llmModel = AutoModelForCausalLM.from_pretrained(\n",
        "                preloadedModelId,\n",
        "                token=hfToken,\n",
        "                torch_dtype=torch.float16, # Use float16 to save memory\n",
        "                device_map=\"auto\", # Automatically distribute layers across CPU/GPU(s)\n",
        "            )\n",
        "            print(\"Model pre-loaded successfully using Transformers library.\")\n",
        "            # Note: self.device will be the primary device, but model might be split.\n",
        "            # HookedTransformer handles this when wrapping the hf_model.\n",
        "            print(f\"Model device map: {self.llmModel.hf_device_map}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error pre-loading model with Transformers: {e}\")\n",
        "            print(\"\\nPotential reasons & solutions:\")\n",
        "            print(\"- Ensure 'accelerate' is installed (`pip install accelerate`).\")\n",
        "            print(\"- Ensure you have enough RAM (CPU loading) or VRAM (GPU loading). Llama-7B needs ~14GB for float16.\")\n",
        "            print(\"- Double-check authentication (token/login) and model access permissions on Hugging Face.\")\n",
        "            print(\"- Check for typos in the model ID.\")\n",
        "            exit(1) # Exit if model pre-loading fails\n",
        "\n",
        "    @staticmethod\n",
        "    def deriveAssistantModel(model : HookedTransformer, earlyExitLayer : int):\n",
        "        \"\"\"\n",
        "        Creates a new HookedTransformer instance that is a shallow copy of the\n",
        "        original but truncates the layers at the specified earlyExitLayer.\n",
        "        Weights are shared initially, but gradients won't flow back to the original.\n",
        "\n",
        "        Args:\n",
        "            model (HookedTransformer): The source model.\n",
        "            earlyExitLayer (int): The layer index (0-based) *after* which to truncate.\n",
        "                                   The assistant model will have layers 0 to earlyExitLayer-1.\n",
        "\n",
        "        Returns:\n",
        "            HookedTransformer: A new model instance with truncated layers.\n",
        "        \"\"\"\n",
        "        if not (0 < earlyExitLayer <= model.cfg.n_layers):\n",
        "            raise ValueError(f\"earlyExitLayer must be between 1 and {model.cfg.n_layers}\")\n",
        "\n",
        "        print(f\"Deriving assistant model exiting AFTER layer {earlyExitLayer - 1}\")\n",
        "        # Create a shallow copy of the config and modify it\n",
        "        new_cfg = deepcopy(model.cfg)\n",
        "        new_cfg.n_layers = earlyExitLayer\n",
        "\n",
        "        # Create a new HookedTransformer with the modified config\n",
        "        # This avoids deepcopying the entire model structure unnecessarily\n",
        "        assistantModel = HookedTransformer(new_cfg)\n",
        "\n",
        "        # Copy weights/buffers from the original model to the new truncated model\n",
        "        # This ensures parameters are shared where layers overlap\n",
        "        original_state_dict = model.state_dict()\n",
        "        assistant_state_dict = assistantModel.state_dict()\n",
        "\n",
        "        # Filter original state dict to only include keys present in the assistant model\n",
        "        filtered_state_dict = {\n",
        "            k: v for k, v in original_state_dict.items() if k in assistant_state_dict\n",
        "        }\n",
        "\n",
        "        # Load the filtered state dict\n",
        "        assistantModel.load_state_dict(filtered_state_dict, strict=False) # strict=False allows missing keys (the truncated layers)\n",
        "\n",
        "        # Ensure the new model is on the same device as the original\n",
        "        assistantModel = assistantModel.to(model.cfg.device)\n",
        "        assistantModel.eval() # Set to evaluation mode\n",
        "\n",
        "        print(f\"Assistant model created with {assistantModel.cfg.n_layers} layers.\")\n",
        "        return assistantModel\n",
        "\n",
        "\n",
        "    def setModel(self, model : HookedTransformer):\n",
        "        \"\"\"\n",
        "        Allows replacing the model and tokenizer used by the experiment instance.\n",
        "        Useful for analyzing a derived model (e.g., early exit).\n",
        "\n",
        "        Args:\n",
        "            model (HookedTransformer): The new HookedTransformer model to use.\n",
        "        \"\"\"\n",
        "        print(f\"Setting experiment model to: {model.cfg.model_name} ({model.cfg.n_layers} layers)\")\n",
        "        self.model = model\n",
        "        # Assume the new model comes with its own tokenizer or reuse if compatible\n",
        "        if hasattr(model, 'tokenizer') and model.tokenizer:\n",
        "            self.tokenizer = model.tokenizer\n",
        "        else:\n",
        "            print(\"Warning: New model does not have a tokenizer attached. Reusing the previous one.\")\n",
        "            if self.tokenizer is None:\n",
        "                 raise ValueError(\"Cannot set model without tokenizer if no tokenizer was previously loaded.\")\n",
        "        self.modelId = model.cfg.model_name # Update modelId reference\n",
        "\n",
        "\n",
        "    def calculateLogProbContributionPerToken(self, inputText: str, maxNewTokens: int = 1) -> list[dict[int, float]]:\n",
        "        \"\"\"\n",
        "        Calculates the log probability contribution of each model component (embedding,\n",
        "        attention blocks, MLP blocks) for each token generated.\n",
        "\n",
        "        Args:\n",
        "            inputText (str): The input prompt.\n",
        "            maxNewTokens (int): The number of tokens to generate and analyze. Defaults to 1.\n",
        "\n",
        "        Returns:\n",
        "            list[dict[int, float]]: A list where each element corresponds to a generated token.\n",
        "                                     Each dictionary maps a sub-layer index to its log probability\n",
        "                                     contribution for the *actually predicted* token at that step.\n",
        "                                     Index 0: Embedding contribution.\n",
        "                                     Index 1: Layer 0 Attention contribution.\n",
        "                                     Index 2: Layer 0 MLP contribution.\n",
        "                                     Index 3: Layer 1 Attention contribution.\n",
        "                                     ... and so on.\n",
        "        \"\"\"\n",
        "        if not self.model or not self.tokenizer:\n",
        "            print(\"Error: Model or tokenizer not loaded.\")\n",
        "            return []\n",
        "\n",
        "        tokens = self.tokenizer.encode(inputText, return_tensors=\"pt\").to(self.device)\n",
        "        generatedTokens = tokens.clone()\n",
        "        allStepsContributions: list[dict[int, float]] = []\n",
        "\n",
        "        self.model.eval() # Ensure model is in eval mode\n",
        "        with torch.no_grad(): # Disable gradients for inference\n",
        "            for step in range(maxNewTokens):\n",
        "                # Get logits and activations for the current sequence\n",
        "                logits, cache = self.model.run_with_cache(generatedTokens, remove_batch_dim=True) # remove_batch_dim=True simplifies indexing\n",
        "\n",
        "                # Get the ID of the token predicted for the *next* position\n",
        "                # Logits shape: [seq_len, d_vocab]\n",
        "                finalPredictedTokenId: int = torch.argmax(logits[-1, :]).item() # Logits for the last token position\n",
        "\n",
        "                # --- Calculate Log Probability Contributions ---\n",
        "                # We calculate the log_softmax of the output of each component *projected to the vocab space*,\n",
        "                # and take the value corresponding to the final predicted token ID.\n",
        "                currentStepContributions: dict[int, float] = {}\n",
        "                subLayerCounter = 1 # Start from 1 for layer blocks\n",
        "\n",
        "                # Embedding Contribution (applied to the residual stream *before* layer 0)\n",
        "                # Note: TransformerLens cache['hook_embed'] and cache['hook_pos_embed'] contain the embeddings themselves.\n",
        "                # The contribution comes from the initial state passed into the first layer's normalization.\n",
        "                # We often approximate this by looking at the residual stream *before* any blocks.\n",
        "                # Let's use cache[\"blocks.0.hook_resid_pre\"] which is the state input to layer 0.\n",
        "                # If the model doesn't have pre-LN norm, use 'hook_embed' + 'hook_pos_embed' or just 'hook_resid_pre' if available at layer 0.\n",
        "\n",
        "                # Use residual stream state *before* Layer 0 as the \"initial\" state\n",
        "                if \"blocks.0.hook_resid_pre\" in cache:\n",
        "                    initial_resid = cache[\"blocks.0.hook_resid_pre\"] # Shape [seq_len, d_model]\n",
        "                elif \"ln_final.hook_normalized\" in cache:\n",
        "                    # If no resid_pre, maybe infer based on final norm input if absolutely necessary (less ideal)\n",
        "                    # This is complex, let's stick to the documented direct contributions if possible.\n",
        "                    # A simpler approximation: Use the embedding layer output directly.\n",
        "                    # This ignores positional encoding's direct effect but captures token embedding.\n",
        "                    embed_output = cache['hook_embed'] # Output of token embedding lookup\n",
        "                    if 'hook_pos_embed' in cache:\n",
        "                        embed_output += cache['hook_pos_embed'] # Add positional embedding if separate\n",
        "                    initial_resid = embed_output # Approximate initial state\n",
        "                else:\n",
        "                     print(\"Warning: Could not find 'blocks.0.hook_resid_pre' or 'hook_embed' in cache. Skipping embedding contribution.\")\n",
        "                     initial_resid = None\n",
        "\n",
        "                if initial_resid is not None:\n",
        "                    # Unembed the state *at the last sequence position*\n",
        "                    embedLogits = self.model.unembed(self.model.ln_final(initial_resid[-1, :])) # Apply final LayerNorm + Unembed\n",
        "                    embedLogProb: float = log_softmax(embedLogits, dim=-1)[finalPredictedTokenId].item()\n",
        "                    currentStepContributions[0] = embedLogProb # Use 0 for \"embedding\"/initial state\n",
        "\n",
        "                # Layer Contributions (Attention and MLP blocks)\n",
        "                for layerIdx in range(self.model.cfg.n_layers):\n",
        "                    # Attention Residual Block Contribution\n",
        "                    # hook_attn_out is the output of the attention block *added* to the residual stream input\n",
        "                    # We want the *direct* output of the attention block *before* the addition.\n",
        "                    # TransformerLens provides specific hooks for this: `hook_z` (output of attention heads after W_O)\n",
        "                    if f\"blocks.{layerIdx}.attn.hook_z\" in cache:\n",
        "                        attnOut = cache[f\"blocks.{layerIdx}.attn.hook_z\"] # Shape [seq_len, num_heads, d_head] -> effectively [seq_len, d_model] after W_O\n",
        "                        # Unembed the output *at the last sequence position* after applying final LayerNorm\n",
        "                        # Apply final LN to simulate its effect if this output were the final state\n",
        "                        attnLogits = self.model.unembed(self.model.ln_final(attnOut[-1, :]))\n",
        "                        attnLogProb: float = log_softmax(attnLogits, dim=-1)[finalPredictedTokenId].item()\n",
        "                        currentStepContributions[subLayerCounter] = attnLogProb\n",
        "                    else:\n",
        "                        print(f\"Warning: Cache key 'blocks.{layerIdx}.attn.hook_z' not found. Skipping Attn L{layerIdx} contribution.\")\n",
        "                        currentStepContributions[subLayerCounter] = 0.0 # Or float('nan')\n",
        "                    subLayerCounter += 1\n",
        "\n",
        "                    # MLP Residual Block Contribution\n",
        "                    # hook_mlp_out is the output of the MLP block *added* to the residual stream input.\n",
        "                    # We want the direct output before addition. `hook_post` inside the MLP block usually captures this.\n",
        "                    if f\"blocks.{layerIdx}.mlp.hook_post\" in cache:\n",
        "                        mlpOut = cache[f\"blocks.{layerIdx}.mlp.hook_post\"] # Shape [seq_len, d_model]\n",
        "                        # Unembed the output *at the last sequence position* after applying final LayerNorm\n",
        "                        mlpLogits = self.model.unembed(self.model.ln_final(mlpOut[-1, :]))\n",
        "                        mlpLogProb: float = log_softmax(mlpLogits, dim=-1)[finalPredictedTokenId].item()\n",
        "                        currentStepContributions[subLayerCounter] = mlpLogProb\n",
        "                    else:\n",
        "                         print(f\"Warning: Cache key 'blocks.{layerIdx}.mlp.hook_post' not found. Skipping MLP L{layerIdx} contribution.\")\n",
        "                         currentStepContributions[subLayerCounter] = 0.0 # Or float('nan')\n",
        "                    subLayerCounter += 1\n",
        "\n",
        "\n",
        "                allStepsContributions.append(currentStepContributions)\n",
        "\n",
        "                # Add the predicted token to the sequence for the next step\n",
        "                generatedTokens = torch.cat(\n",
        "                    (generatedTokens, torch.tensor([[finalPredictedTokenId]], device=self.device)),\n",
        "                    dim=-1\n",
        "                )\n",
        "\n",
        "        self.logitContributionsPerToken.extend(allStepsContributions) # Store if needed later\n",
        "        return allStepsContributions\n",
        "\n",
        "    def computeAverageLogitContributionPerToken(self, prompts: list[str], maxNewTokens: int = 1) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Computes the average log probability contribution per sub-layer across multiple prompts\n",
        "        and potentially multiple generated tokens per prompt.\n",
        "\n",
        "        Args:\n",
        "            prompts (list[str]): A list of input prompts.\n",
        "            maxNewTokens (int): The number of tokens to generate and analyze for *each* prompt. Defaults to 1.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: A DataFrame containing the average log probability contribution\n",
        "                          for each sub-layer index across all analyzed tokens. Returns an empty\n",
        "                          DataFrame if no contributions were calculated.\n",
        "        \"\"\"\n",
        "        allPromptsContributions: list[dict[int, float]] = []\n",
        "        total_tokens_analyzed = 0\n",
        "\n",
        "        for prompt in prompts:\n",
        "            print(f\"\\nProcessing prompt: '{prompt}'\")\n",
        "            contributions = self.calculateLogProbContributionPerToken(prompt, maxNewTokens)\n",
        "            if contributions:\n",
        "                 allPromptsContributions.extend(contributions)\n",
        "                 total_tokens_analyzed += len(contributions)\n",
        "                 # Optional: print predicted tokens for this prompt\n",
        "                 # predicted_ids = [max(step_contrib, key=step_contrib.get) for step_contrib in contributions] # This is wrong logic\n",
        "                 # predicted_tokens_str = [self.tokenizer.decode([id]) for id in predicted_ids] # Need actual prediction logic here\n",
        "                 # print(f\"Analyzed {len(contributions)} predicted tokens.\") #: {predicted_tokens_str}\") # Can't easily get token str here\n",
        "            else:\n",
        "                 print(f\"Skipping prompt '{prompt}' due to issues during contribution calculation.\")\n",
        "\n",
        "\n",
        "        if not allPromptsContributions:\n",
        "            print(\"Warning: No contributions were collected from any prompt.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        print(f\"\\nCollected contributions for a total of {total_tokens_analyzed} predicted tokens across {len(prompts)} prompts.\")\n",
        "\n",
        "        # Aggregate contributions for averaging\n",
        "        averageContributions = {} # key: subLayerIdx, value: list of contributions\n",
        "        for stepContributions in allPromptsContributions:\n",
        "            for subLayerIdx, contribution in stepContributions.items():\n",
        "                if subLayerIdx not in averageContributions:\n",
        "                    averageContributions[subLayerIdx] = []\n",
        "                averageContributions[subLayerIdx].append(contribution)\n",
        "\n",
        "        # Calculate average for each sub-layer\n",
        "        averageResults = {} # key: subLayerIdx, value: average contribution\n",
        "        for subLayerIdx, values in averageContributions.items():\n",
        "            if values:\n",
        "                averageResults[subLayerIdx] = sum(values) / len(values)\n",
        "            else:\n",
        "                averageResults[subLayerIdx] = float('nan') # Should not happen if collection worked\n",
        "\n",
        "        # Create DataFrame\n",
        "        dfAverageContributions = pd.DataFrame.from_dict(averageResults, orient='index', columns=['Average Log Probability'])\n",
        "        dfAverageContributions.index.name = 'Sub-Layer Index' # Changed name for clarity\n",
        "        dfAverageContributions = dfAverageContributions.sort_index() # Sort by sub-layer index\n",
        "\n",
        "        return dfAverageContributions\n",
        "\n",
        "    # --- Visualization Methods ---\n",
        "\n",
        "    def _get_sub_layer_label(self, idx: int) -> str:\n",
        "        \"\"\"Helper function to create a readable label for a sub-layer index.\"\"\"\n",
        "        if idx == 0:\n",
        "            return \"Embedding\"\n",
        "        layer = (idx - 1) // 2\n",
        "        block_type = \"Attention\" if (idx - 1) % 2 == 0 else \"MLP\"\n",
        "        return f\"L{layer} {block_type}\"\n",
        "\n",
        "    def visualizeSingleTokenContributions(self, contributions: dict[int, float], tokenStr: str = \"Predicted Token\"):\n",
        "        \"\"\"\n",
        "        Visualizes the log probability contributions per sub-layer for a single token prediction.\n",
        "\n",
        "        Args:\n",
        "            contributions (dict[int, float]): The dictionary of contributions for one token\n",
        "                                             (output from calculateLogProbContributionPerToken).\n",
        "            tokenStr (str): A string representation of the predicted token for the plot title.\n",
        "        \"\"\"\n",
        "        if not contributions:\n",
        "            print(\"Contributions dictionary is empty. Cannot visualize.\")\n",
        "            return\n",
        "\n",
        "        df_plot = pd.DataFrame(list(contributions.items()), columns=['Sub-Layer Index', 'Log Probability'])\n",
        "        df_plot['Sub-Layer Label'] = df_plot['Sub-Layer Index'].apply(self._get_sub_layer_label)\n",
        "        df_plot = df_plot.sort_values('Sub-Layer Index') # Ensure correct order\n",
        "\n",
        "        plt.figure(figsize=(max(10, len(df_plot) * 0.4), 6)) # Adjust width based on number of layers\n",
        "        barplot = sns.barplot(x='Sub-Layer Label', y='Log Probability', data=df_plot, palette=\"viridis\")\n",
        "        plt.title(f'Log Prob Contribution per Component for token \"{tokenStr}\" ({self.model.cfg.model_name})')\n",
        "        plt.xlabel('Model Component')\n",
        "        plt.ylabel('Log Probability Contribution')\n",
        "        plt.xticks(rotation=70, ha='right')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Add text labels on bars\n",
        "        for p in barplot.patches:\n",
        "             barplot.annotate(format(p.get_height(), '.2f'),\n",
        "                           (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                           ha = 'center', va = 'center',\n",
        "                           xytext = (0, 9),\n",
        "                           textcoords = 'offset points')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def visualizeAverageSubLayerContribution(self, averageContributionsDf: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Visualizes the average log probability contributions per sub-layer,\n",
        "        typically computed over multiple prompts/tokens.\n",
        "\n",
        "        Args:\n",
        "            averageContributionsDf (pd.DataFrame): DataFrame output from computeAverageLogitContributionPerToken.\n",
        "        \"\"\"\n",
        "        if averageContributionsDf.empty:\n",
        "            print(\"DataFrame is empty. Cannot visualize average sub-layer contributions.\")\n",
        "            return\n",
        "\n",
        "        df_plot = averageContributionsDf.reset_index()\n",
        "        df_plot['Sub-Layer Label'] = df_plot['Sub-Layer Index'].apply(self._get_sub_layer_label)\n",
        "        df_plot = df_plot.sort_values('Sub-Layer Index') # Ensure correct order\n",
        "\n",
        "        plt.figure(figsize=(max(10, len(df_plot) * 0.4), 6)) # Adjust width based on number of layers\n",
        "        barplot = sns.barplot(x='Sub-Layer Label', y='Average Log Probability', data=df_plot, palette=\"viridis\")\n",
        "        plt.title(f'Average Log Prob Contribution per Component ({self.model.cfg.model_name})')\n",
        "        plt.xlabel('Model Component')\n",
        "        plt.ylabel('Average Log Probability Contribution')\n",
        "        plt.xticks(rotation=70, ha='right')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Add text labels on bars\n",
        "        for p in barplot.patches:\n",
        "             barplot.annotate(format(p.get_height(), '.2f'),\n",
        "                           (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                           ha = 'center', va = 'center',\n",
        "                           xytext = (0, 9),\n",
        "                           textcoords = 'offset points')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def visualizeCumulativeContribution(self, contributions: dict[int, float], tokenStr: str = \"Predicted Token\"):\n",
        "        \"\"\"\n",
        "        Visualizes the cumulative sum of log probability contributions across components\n",
        "        for a single token prediction.\n",
        "\n",
        "        Args:\n",
        "            contributions (dict[int, float]): Dictionary of contributions for one token.\n",
        "            tokenStr (str): String representation of the predicted token for the plot title.\n",
        "        \"\"\"\n",
        "        if not contributions:\n",
        "            print(\"Contributions dictionary is empty. Cannot visualize cumulative sum.\")\n",
        "            return\n",
        "\n",
        "        # Sort contributions by sub-layer index for correct cumulative sum order\n",
        "        sorted_items = sorted(contributions.items())\n",
        "        indices, values = zip(*sorted_items)\n",
        "        cumulative_values = np.cumsum(values)\n",
        "        labels = [self._get_sub_layer_label(idx) for idx in indices]\n",
        "\n",
        "        plt.figure(figsize=(max(10, len(labels) * 0.4), 6))\n",
        "        plt.plot(labels, cumulative_values, marker='o', linestyle='-', color='blue', label='Cumulative Log Prob')\n",
        "\n",
        "        # Optionally overlay the individual contributions as bars for context\n",
        "        plt.bar(labels, values, alpha=0.3, color='orange', label='Individual Contribution')\n",
        "\n",
        "        plt.title(f'Cumulative Log Prob Contribution for token \"{tokenStr}\" ({self.model.cfg.model_name})')\n",
        "        plt.xlabel('Model Component (Processed Order)')\n",
        "        plt.ylabel('Log Probability')\n",
        "        plt.xticks(rotation=70, ha='right')\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def visualizeAverageCumulativeContribution(self, averageContributionsDf: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Visualizes the cumulative sum of *average* log probability contributions\n",
        "        across components.\n",
        "\n",
        "        Args:\n",
        "            averageContributionsDf (pd.DataFrame): DataFrame output from computeAverageLogitContributionPerToken.\n",
        "        \"\"\"\n",
        "        if averageContributionsDf.empty:\n",
        "            print(\"DataFrame is empty. Cannot visualize average cumulative contributions.\")\n",
        "            return\n",
        "\n",
        "        df_plot = averageContributionsDf.reset_index().sort_values('Sub-Layer Index') # Ensure order\n",
        "        values = df_plot['Average Log Probability'].values\n",
        "        cumulative_values = np.cumsum(values)\n",
        "        labels = [self._get_sub_layer_label(idx) for idx in df_plot['Sub-Layer Index']]\n",
        "\n",
        "        plt.figure(figsize=(max(10, len(labels) * 0.4), 6))\n",
        "        plt.plot(labels, cumulative_values, marker='o', linestyle='-', color='blue', label='Cumulative Avg Log Prob')\n",
        "\n",
        "        # Optionally overlay the individual average contributions as bars\n",
        "        plt.bar(labels, values, alpha=0.3, color='orange', label='Individual Avg Contribution')\n",
        "\n",
        "        plt.title(f'Average Cumulative Log Prob Contribution ({self.model.cfg.model_name})')\n",
        "        plt.xlabel('Model Component (Processed Order)')\n",
        "        plt.ylabel('Average Log Probability')\n",
        "        plt.xticks(rotation=70, ha='right')\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "nFulkje32g6D"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# Example Usage\n",
        "# =====================================================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- Configuration ---\n",
        "    # Option 1: Use a small, public model (no token needed)\n",
        "    # model_id_to_use = \"gpt2\"\n",
        "    # model_id_to_use = \"EleutherAI/pythia-160m\"\n",
        "    model_id_to_use = llama_model_name # Smaller, good for quick tests\n",
        "    hf_token_to_use = None         # Not needed for public models\n",
        "    preload_model_id = model_id      # Not needed for direct TLens loading\n",
        "\n",
        "    # Option 2: Use a larger or gated model (e.g., Llama 2/3, Mistral)\n",
        "    # Requires access grant on Hugging Face and authentication.\n",
        "    # model_id_to_use = \"meta-llama/Llama-2-7b-chat-hf\" # TLens might map this internally\n",
        "    # preload_model_id = \"meta-llama/Llama-2-7b-chat-hf\" # Use same ID for preloading\n",
        "    # Set your HF token below OR ensure HUGGINGFACE_TOKEN env var is set\n",
        "    # hf_token_to_use = \"hf_YOUR_TOKEN_HERE\" # Replace with your actual token if needed\n",
        "    # if hf_token_to_use == \"hf_YOUR_TOKEN_HERE\": hf_token_to_use=None # Avoid using placeholder\n",
        "\n",
        "    print(f\"--- Initializing Experiment for model: {model_id_to_use} ---\")\n",
        "    try:\n",
        "        experiment = TransformerExperiment(\n",
        "            modelId=model_id_to_use,\n",
        "            hfToken=hf_token_to_use,\n",
        "            preloadedModelId=preload_model_id # Pass None if not preloading\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- FAILED TO INITIALIZE EXPERIMENT ---\")\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Please check model ID, HF token/access, and available resources (RAM/VRAM).\")\n",
        "        exit(1)\n",
        "\n",
        "    # --- 1. Analyze a Single Prompt ---\n",
        "    prompt1 = \"The first human on the Moon was\"\n",
        "    print(f\"\\n--- Analyzing single prompt: '{prompt1}' ---\")\n",
        "\n",
        "    # Calculate contributions for the *next* predicted token (maxNewTokens=1)\n",
        "    contributions_list = experiment.calculateLogProbContributionPerToken(prompt1, maxNewTokens=1)\n",
        "\n",
        "    if contributions_list:\n",
        "        single_token_contributions = contributions_list[0] # Get contributions for the first (only) generated token\n",
        "\n",
        "        # --- Find the predicted token string for visualization titles ---\n",
        "        # Re-run model once without cache just to get the prediction easily\n",
        "        # (Alternatively, grab from the cache calculation if careful about indexing)\n",
        "        tokens = experiment.tokenizer.encode(prompt1, return_tensors=\"pt\").to(experiment.device)\n",
        "        with torch.no_grad():\n",
        "             logits = experiment.model(tokens) # Get logits [batch, seq_len, d_vocab]\n",
        "        predicted_token_id = torch.argmax(logits[0, -1, :]).item() # Prediction for the last position\n",
        "        predicted_token_str = experiment.tokenizer.decode([predicted_token_id])\n",
        "        print(f\"Predicted next token: '{predicted_token_str}' (ID: {predicted_token_id})\")\n",
        "        print(f\"Contributions calculated for {len(single_token_contributions)} components.\")\n",
        "\n",
        "        # Visualize contributions for this single token prediction\n",
        "        print(\"\\nVisualizing individual component contributions...\")\n",
        "        experiment.visualizeSingleTokenContributions(\n",
        "            single_token_contributions,\n",
        "            tokenStr=predicted_token_str\n",
        "        )\n",
        "\n",
        "        # Visualize cumulative contributions for this single token prediction\n",
        "        print(\"\\nVisualizing cumulative component contributions...\")\n",
        "        experiment.visualizeCumulativeContribution(\n",
        "            single_token_contributions,\n",
        "            tokenStr=predicted_token_str\n",
        "        )\n",
        "    else:\n",
        "        print(\"Could not calculate contributions for the single prompt.\")\n",
        "\n",
        "    # --- 2. Analyze Average Contributions Over Multiple Prompts ---\n",
        "    prompts_for_avg = [\n",
        "        \"Artificial intelligence is transforming\",\n",
        "        \"The capital of Germany is\",\n",
        "        \"To be or not to be, that is the\",\n",
        "        \"Machine learning models require large amounts of\",\n",
        "        \"The theory of relativity was developed by\",\n",
        "    ]\n",
        "    print(f\"\\n--- Analyzing average contributions over {len(prompts_for_avg)} prompts ---\")\n",
        "    # Calculate average contributions for the first predicted token of each prompt\n",
        "    average_contributions_df = experiment.computeAverageLogitContributionPerToken(\n",
        "        prompts_for_avg,\n",
        "        maxNewTokens=1\n",
        "    )\n",
        "\n",
        "    if not average_contributions_df.empty:\n",
        "        print(\"\\nAverage Contributions DataFrame:\")\n",
        "        # Display with more precision\n",
        "        with pd.option_context('display.float_format', '{:,.4f}'.format):\n",
        "            print(average_contributions_df)\n",
        "\n",
        "        # Visualize average sub-layer contributions\n",
        "        print(\"\\nVisualizing average component contributions...\")\n",
        "        experiment.visualizeAverageSubLayerContribution(average_contributions_df)\n",
        "\n",
        "        # Visualize average cumulative contributions\n",
        "        print(\"\\nVisualizing average cumulative component contributions...\")\n",
        "        experiment.visualizeAverageCumulativeContribution(average_contributions_df)\n",
        "    else:\n",
        "        print(\"Could not compute or visualize average contributions.\")\n",
        "\n",
        "    # --- 3. Optional: Early Exit Model Analysis ---\n",
        "    # print(\"\\n--- Optional: Deriving and Analyzing an Early-Exit Model ---\")\n",
        "    # try:\n",
        "    #     # Create a model that exits halfway through the layers\n",
        "    #     n_layers_original = experiment.model.cfg.n_layers\n",
        "    #     early_exit_layer_idx = n_layers_original // 2 # Index of the layer *after* which to exit\n",
        "    #\n",
        "    #     if early_exit_layer_idx > 0:\n",
        "    #         print(f\"Creating assistant model exiting after layer {early_exit_layer_idx - 1} (total {early_exit_layer_idx} layers)\")\n",
        "    #         assistant_model = TransformerExperiment.deriveAssistantModel(experiment.model, early_exit_layer_idx)\n",
        "    #\n",
        "    #         # Create a *new* experiment instance or modify the current one to use the assistant model\n",
        "    #         # Option A: New instance (cleaner)\n",
        "    #         assistant_experiment = TransformerExperiment(modelId=f\"{experiment.modelId}-exit{early_exit_layer_idx}\")\n",
        "    #         assistant_experiment.setModel(assistant_model) # Set the derived model\n",
        "    #\n",
        "    #         # Now run analyses on the assistant_experiment...\n",
        "    #         print(f\"\\nAnalyzing assistant model with prompt: '{prompt1}'\")\n",
        "    #         assistant_contributions = assistant_experiment.calculateLogProbContributionPerToken(prompt1, maxNewTokens=1)\n",
        "    #\n",
        "    #         if assistant_contributions:\n",
        "    #             # Get predicted token for assistant\n",
        "    #             tokens_asst = assistant_experiment.tokenizer.encode(prompt1, return_tensors=\"pt\").to(assistant_experiment.device)\n",
        "    #             with torch.no_grad():\n",
        "    #                  logits_asst = assistant_experiment.model(tokens_asst)\n",
        "    #             pred_id_asst = torch.argmax(logits_asst[0, -1, :]).item()\n",
        "    #             pred_str_asst = assistant_experiment.tokenizer.decode([pred_id_asst])\n",
        "    #             print(f\"Assistant model predicted token: '{pred_str_asst}'\")\n",
        "    #\n",
        "    #             assistant_experiment.visualizeSingleTokenContributions(assistant_contributions[0], tokenStr=pred_str_asst)\n",
        "    #             assistant_experiment.visualizeCumulativeContribution(assistant_contributions[0], tokenStr=pred_str_asst)\n",
        "    #         else:\n",
        "    #             print(\"Could not calculate contributions for the assistant model.\")\n",
        "    #\n",
        "    #         del assistant_model # Clean up model if needed\n",
        "    #         del assistant_experiment\n",
        "    #     else:\n",
        "    #         print(\"Model has too few layers to create a meaningful early exit version.\")\n",
        "    #\n",
        "    # except Exception as e:\n",
        "    #      print(f\"Error during early-exit analysis: {e}\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- Experiment Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "gDgsmtZ7b7e9",
        "outputId": "36878179-c93a-41d0-b2a6-3f8caf9305af"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing Experiment for model: meta-llama/Llama-3.2-1B ---\n",
            "Using device: cuda\n",
            "Attempting to load model without explicit token (relies on CLI login or cached credentials).\n",
            "--- Pre-loading Hugging Face Model: facebook/layerskip-llama3.2-1B ---\n",
            "Pre-loading tokenizer for model: facebook/layerskip-llama3.2-1B\n",
            "Tokenizer pre-loaded successfully.\n",
            "Pre-loading model: facebook/layerskip-llama3.2-1B\n",
            "This may take a while and require significant RAM/VRAM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1569: UserWarning: Current model requires 64 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model pre-loaded successfully using Transformers library.\n",
            "Model device map: {'': 'cpu'}\n",
            "Loading HookedTransformer wrapping preloaded model: facebook/layerskip-llama3.2-1B\n",
            "Error loading HookedTransformer from preloaded model facebook/layerskip-llama3.2-1B: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 896.00 KiB is free. Process 18747 has 39.55 GiB memory in use. Of the allocated memory 39.01 GiB is allocated by PyTorch, and 48.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Falling back to default loading mechanism for modelId: meta-llama/Llama-3.2-1B\n",
            "Loading model 'meta-llama/Llama-3.2-1B' directly with TransformerLens...\n",
            "Error loading model meta-llama/Llama-3.2-1B directly with TransformerLens: 'token'\n",
            "Check model name, internet connection, and HF credentials/access.\n",
            "\n",
            "--- FAILED TO INITIALIZE EXPERIMENT ---\n",
            "Error: 'token'\n",
            "Please check model ID, HF token/access, and available resources (RAM/VRAM).\n",
            "\n",
            "--- Analyzing single prompt: 'The first human on the Moon was' ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'experiment' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-8d76cc5b1141>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Calculate contributions for the *next* predicted token (maxNewTokens=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mcontributions_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateLogProbContributionPerToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxNewTokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontributions_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'experiment' is not defined"
          ]
        }
      ]
    }
  ]
}